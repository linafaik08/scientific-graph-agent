{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a003e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDemo notebook for Scientific Graph Agent.\\n\\nThis script demonstrates:\\n1. Basic usage of the agent graph\\n2. Memory functionality across multiple queries\\n3. Graph visualization\\n4. How the conditional loop works\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Demo notebook for Scientific Graph Agent.\n",
    "\n",
    "This script demonstrates:\n",
    "1. Basic usage of the agent graph\n",
    "2. Memory functionality across multiple queries\n",
    "3. Graph visualization\n",
    "4. How the conditional loop works\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7de14f",
   "metadata": {},
   "source": [
    "# üß™ Scientific Graph Agent - Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e943173",
   "metadata": {},
   "source": [
    "This notebook demonstrates a simple agent graph for scientific paper exploration using LangGraph + ArXiv API with memory support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e2a928a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ced08c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_MODEL = \"gpt-5-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa1950f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment variables loaded\n"
     ]
    }
   ],
   "source": [
    "# Verify that API keys are set\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"‚ö†Ô∏è  OPENAI_API_KEY not found in .env file\")\n",
    "\n",
    "print(\"‚úÖ Environment variables loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc756288",
   "metadata": {},
   "source": [
    "## Graph Agent Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e7e4d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Graph compiled with memory enabled\n",
      "‚úÖ Agent graph created\n"
     ]
    }
   ],
   "source": [
    "from src.agent_graph import create_graph, AgentState\n",
    "\n",
    "# Create graph with custom parameters\n",
    "graph = create_graph(with_checkpointer=True)\n",
    "\n",
    "print(\"‚úÖ Agent graph created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a01e19",
   "metadata": {},
   "source": [
    "### Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1e2eae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph structure:\n",
      "START ‚Üí clarifier ‚Üí researcher ‚Üí summarizer ‚Üí END\n",
      "           ‚Üë            ‚Üì\n",
      "           ‚îî‚îÄ(if <3 papers)\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "    \n",
    "# Generate graph visualization as PNG\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "print(\"Graph structure:\")\n",
    "print(\"START ‚Üí clarifier ‚Üí researcher ‚Üí summarizer ‚Üí END\")\n",
    "print(\"           ‚Üë            ‚Üì\")\n",
    "print(\"           ‚îî‚îÄ(if <3 papers)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1090516",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce34676",
   "metadata": {},
   "source": [
    "### Test 1: Simple Research Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "193d6be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting agent graph execution...\n",
      "\n",
      "üéØ Clarifying query: 'What are the key innovations in transformer architectures?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 17:56:19,425 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-21 17:56:19,439 - INFO - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=transformer+innovations+self-attention+multi-head+positional+encodings+residual+connections+layernorm&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ú® Refined query: 'transformer innovations self-attention multi-head positional encodings residual connections layernorm'\n",
      "üîç Searching ArXiv: 'transformer innovations self-attention multi-head positional encodings residual connections layernorm' (iteration 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 17:56:20,454 - INFO - Got first page: 100 of 562453 total results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Found 5 papers\n",
      "üìù Synthesizing 5 papers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 17:56:44,865 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Summary generated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the key innovations in transformer architectures?',\n",
       " 'refined_query': 'transformer innovations self-attention multi-head positional encodings residual connections layernorm',\n",
       " 'papers': [{'title': 'Exploring the Impact of Layer Normalization for Zero-shot Neural Machine Translation',\n",
       "   'authors': ['Zhuoyuan Mao',\n",
       "    'Raj Dabre',\n",
       "    'Qianying Liu',\n",
       "    'Haiyue Song',\n",
       "    'Chenhui Chu',\n",
       "    'Sadao Kurohashi'],\n",
       "   'summary': 'This paper studies the impact of layer normalization (LayerNorm) on zero-shot\\ntranslation (ZST). Recent efforts for ZST often utilize the Transformer\\narchitecture as the backbone, with LayerNorm at the input of layers (PreNorm)\\nset as the default. However, Xu et al. (2019) has revealed that PreNorm carries\\nthe risk of overfitting the training data. Based on this, we hypothesize that\\nPreNorm may overfit supervised directions and thus have low generalizability\\nfor ZST. Through experiments on OPUS, IWSLT, and Europarl datasets for 54 ZST\\ndirections, we demonstrate that the original Transformer setting of LayerNorm\\nafter residual connections (PostNorm) consistently outperforms PreNorm by up to\\n12.3 BLEU points. We then study the performance disparities by analyzing the\\ndifferences in off-target rates and structural variations between PreNorm and\\nPostNorm. This study highlights the need for careful consideration of the\\nLayerNorm setting for ZST.',\n",
       "   'url': 'http://arxiv.org/abs/2305.09312v1',\n",
       "   'published': '2023-05-16'},\n",
       "  {'title': 'LayerNorm: A key component in parameter-efficient fine-tuning',\n",
       "   'authors': ['Taha ValizadehAslani', 'Hualou Liang'],\n",
       "   'summary': 'Fine-tuning a pre-trained model, such as Bidirectional Encoder\\nRepresentations from Transformers (BERT), has been proven to be an effective\\nmethod for solving many natural language processing (NLP) tasks. However, due\\nto the large number of parameters in many state-of-the-art NLP models,\\nincluding BERT, the process of fine-tuning is computationally expensive. One\\nattractive solution to this issue is parameter-efficient fine-tuning, which\\ninvolves modifying only a minimal segment of the model while keeping the\\nremainder unchanged. Yet, it remains unclear which segment of the BERT model is\\ncrucial for fine-tuning. In this paper, we first analyze different components\\nin the BERT model to pinpoint which one undergoes the most significant changes\\nafter fine-tuning. We find that output LayerNorm changes more than any other\\ncomponents when fine-tuned for different General Language Understanding\\nEvaluation (GLUE) tasks. Then we show that only fine-tuning the LayerNorm can\\nreach comparable, or in some cases better, performance to full fine-tuning and\\nother parameter-efficient fine-tuning methods. Moreover, we use Fisher\\ninformation to determine the most critical subset of LayerNorm and demonstrate\\nthat many NLP tasks in the GLUE benchmark can be solved by fine-tuning only a\\nsmall portion of LayerNorm with negligible performance degradation.',\n",
       "   'url': 'http://arxiv.org/abs/2403.20284v1',\n",
       "   'published': '2024-03-29'},\n",
       "  {'title': 'Transformer Meets Twicing: Harnessing Unattended Residual Information',\n",
       "   'authors': ['Laziz Abdullaev', 'Tan M. Nguyen'],\n",
       "   'summary': 'Transformer-based deep learning models have achieved state-of-the-art\\nperformance across numerous language and vision tasks. While the self-attention\\nmechanism, a core component of transformers, has proven capable of handling\\ncomplex data patterns, it has been observed that the representational capacity\\nof the attention matrix degrades significantly across transformer layers,\\nthereby hurting its overall performance. In this work, we leverage the\\nconnection between self-attention computations and low-pass non-local means\\n(NLM) smoothing filters and propose the Twicing Attention, a novel attention\\nmechanism that uses kernel twicing procedure in nonparametric regression to\\nalleviate the low-pass behavior of associated NLM smoothing with compelling\\ntheoretical guarantees and enhanced adversarial robustness. This approach\\nenables the extraction and reuse of meaningful information retained in the\\nresiduals following the imperfect smoothing operation at each layer. Our\\nproposed method offers two key advantages over standard self-attention: 1) a\\nprovably slower decay of representational capacity and 2) improved robustness\\nand accuracy across various data modalities and tasks. We empirically\\ndemonstrate the performance gains of our model over baseline transformers on\\nmultiple tasks and benchmarks, including image classification and language\\nmodeling, on both clean and corrupted data.',\n",
       "   'url': 'http://arxiv.org/abs/2503.00687v3',\n",
       "   'published': '2025-03-02'},\n",
       "  {'title': 'BERT Busters: Outlier Dimensions that Disrupt Transformers',\n",
       "   'authors': ['Olga Kovaleva',\n",
       "    'Saurabh Kulshreshtha',\n",
       "    'Anna Rogers',\n",
       "    'Anna Rumshisky'],\n",
       "   'summary': 'Multiple studies have shown that Transformers are remarkably robust to\\npruning. Contrary to this received wisdom, we demonstrate that pre-trained\\nTransformer encoders are surprisingly fragile to the removal of a very small\\nnumber of features in the layer outputs (<0.0001% of model weights). In case of\\nBERT and other pre-trained encoder Transformers, the affected component is the\\nscaling factors and biases in the LayerNorm. The outliers are high-magnitude\\nnormalization parameters that emerge early in pre-training and show up\\nconsistently in the same dimensional position throughout the model. We show\\nthat disabling them significantly degrades both the MLM loss and the downstream\\ntask performance. This effect is observed across several BERT-family models and\\nother popular pre-trained Transformer architectures, including BART, XLNet and\\nELECTRA; we also show a similar effect in GPT-2.',\n",
       "   'url': 'http://arxiv.org/abs/2105.06990v2',\n",
       "   'published': '2021-05-14'},\n",
       "  {'title': 'FastRE: Towards Fast Relation Extraction with Convolutional Encoder and Improved Cascade Binary Tagging Framework',\n",
       "   'authors': ['Guozheng Li',\n",
       "    'Xu Chen',\n",
       "    'Peng Wang',\n",
       "    'Jiafeng Xie',\n",
       "    'Qiqing Luo'],\n",
       "   'summary': 'Recent work for extracting relations from texts has achieved excellent\\nperformance. However, most existing methods pay less attention to the\\nefficiency, making it still challenging to quickly extract relations from\\nmassive or streaming text data in realistic scenarios. The main efficiency\\nbottleneck is that these methods use a Transformer-based pre-trained language\\nmodel for encoding, which heavily affects the training speed and inference\\nspeed. To address this issue, we propose a fast relation extraction model\\n(FastRE) based on convolutional encoder and improved cascade binary tagging\\nframework. Compared to previous work, FastRE employs several innovations to\\nimprove efficiency while also keeping promising performance. Concretely, FastRE\\nadopts a novel convolutional encoder architecture combined with dilated\\nconvolution, gated unit and residual connection, which significantly reduces\\nthe computation cost of training and inference, while maintaining the\\nsatisfactory performance. Moreover, to improve the cascade binary tagging\\nframework, FastRE first introduces a type-relation mapping mechanism to\\naccelerate tagging efficiency and alleviate relation redundancy, and then\\nutilizes a position-dependent adaptive thresholding strategy to obtain higher\\ntagging accuracy and better model generalization. Experimental results\\ndemonstrate that FastRE is well balanced between efficiency and performance,\\nand achieves 3-10x training speed, 7-15x inference speed faster, and 1/100\\nparameters compared to the state-of-the-art models, while the performance is\\nstill competitive.',\n",
       "   'url': 'http://arxiv.org/abs/2205.02490v2',\n",
       "   'published': '2022-05-05'}],\n",
       " 'summary': '## R√©sum√©\\n‚Ä¢ Le positionnement et le comportement de la normalisation de couche (LayerNorm) dans les blocs Transformer influencent fortement la stabilit√© d\\'entra√Ænement et la g√©n√©ralisation en traduction z√©ro-shot. Des configurations \"PreNorm\" courantes peuvent acc√©l√©rer la convergence mais risquent de suradapter les donn√©es d\\'entra√Ænement, d\\'o√π l\\'int√©r√™t d\\'√©tudier et d\\'ajuster cette composante pour de meilleures performances ZST. Ces choix de normalisation interagissent aussi avec d\\'autres changements d\\'architecture. [Paper 1, Paper 2]\\n\\n‚Ä¢ LayerNorm s\\'av√®re √™tre un levier central pour les m√©thodes de fine-tuning √† param√®tres efficaces : modifier ou geler ses param√®tres permet de r√©duire le co√ªt d\\'adaptation tout en conservant des performances solides. Parall√®lement, certains travaux montrent que de tr√®s petites composantes (dimensions/outliers) dans les sorties des couches peuvent avoir un effet disproportionn√© sur le mod√®le, ce qui invite √† surveiller et r√©guler les facteurs d\\'√©chelle. Contr√¥ler LayerNorm et les dimensions anormales est donc une voie cl√© pour la robustesse et l\\'efficience. [Paper 2, Paper 4]\\n\\n‚Ä¢ Les innovations r√©centes ciblent la perte progressive de capacit√© repr√©sentative de la matrice d\\'attention √† travers les couches ; des m√©canismes qui r√©cup√®rent l\\'information r√©siduelle n√©glig√©e (par ex. ¬´ Twicing ¬ª) am√©liorent la richesse des repr√©sentations et la performance sans changer radicalement la famille Transformer. Ces apports montrent comment redistribuer ou r√©injecter l\\'information r√©siduelle peut restaurer la puissance d\\'expression du r√©seau. [Paper 3]\\n\\n‚Ä¢ En parall√®le des am√©liorations internes des Transformers, des approches architecturales alternatives ou hybrides cherchent √† gagner en vitesse et en co√ªt (p. ex. encodeurs convolutionnels pour l\\'extraction de relations). Ces solutions d√©montrent un compromis pratique : conserver des blocs Transformer l√† o√π leur expressivit√© est cruciale et remplacer ou all√©ger d\\'autres parties pour l\\'efficacit√© √† grande √©chelle. [Paper 5, Paper 3]\\n\\n## R√©f√©rences\\n[Paper 1] Exploring the Impact of Layer Normalization for Zero-shot Neural Machine Translation - Zhuoyuan Mao, Raj Dabre, Qianying Liu (2023-05-16) - http://arxiv.org/abs/2305.09312v1\\n\\n[Paper 2] LayerNorm: A key component in parameter-efficient fine-tuning - Taha ValizadehAslani, Hualou Liang (2024-03-29) - http://arxiv.org/abs/2403.20284v1\\n\\n[Paper 3] Transformer Meets Twicing: Harnessing Unattended Residual Information - Laziz Abdullaev, Tan M. Nguyen (2025-03-02) - http://arxiv.org/abs/2503.00687v3\\n\\n[Paper 4] BERT Busters: Outlier Dimensions that Disrupt Transformers - Olga Kovaleva, Saurabh Kulshreshtha, Anna Rogers (2021-05-14) - http://arxiv.org/abs/2105.06990v2\\n\\n[Paper 5] FastRE: Towards Fast Relation Extraction with Convolutional Encoder and Improved Cascade Binary Tagging Framework - Guozheng Li, Xu Chen, Peng Wang (2022-05-05) - http://arxiv.org/abs/2205.02490v2',\n",
       " 'iteration': 1,\n",
       " 'config': {'llm_model': 'gpt-5-mini',\n",
       "  'llm_temperature': 0,\n",
       "  'max_papers': 5,\n",
       "  'max_iterations': 2},\n",
       " 'messages': [HumanMessage(content='What are the key innovations in transformer architectures?', additional_kwargs={}, response_metadata={}, name='User'),\n",
       "  AIMessage(content='Refined query: transformer innovations self-attention multi-head positional encodings residual connections layernorm', additional_kwargs={}, response_metadata={}, name='Clarifier'),\n",
       "  AIMessage(content='Found 5 papers on ArXiv for query: transformer innovations self-attention multi-head positional encodings residual connections layernorm', additional_kwargs={}, response_metadata={}, name='Researcher'),\n",
       "  AIMessage(content='## R√©sum√©\\n‚Ä¢ Le positionnement et le comportement de la normalisation de couche (LayerNorm) dans les blocs Transformer influencent fortement la stabilit√© d\\'entra√Ænement et la g√©n√©ralisation en traduction z√©ro-shot. Des configurations \"PreNorm\" courantes peuvent acc√©l√©rer la convergence mais risquent de suradapter les donn√©es d\\'entra√Ænement, d\\'o√π l\\'int√©r√™t d\\'√©tudier et d\\'ajuster cette composante pour de meilleures performances ZST. Ces choix de normalisation interagissent aussi avec d\\'autres changements d\\'architecture. [Paper 1, Paper 2]\\n\\n‚Ä¢ LayerNorm s\\'av√®re √™tre un levier central pour les m√©thodes de fine-tuning √† param√®tres efficaces : modifier ou geler ses param√®tres permet de r√©duire le co√ªt d\\'adaptation tout en conservant des performances solides. Parall√®lement, certains travaux montrent que de tr√®s petites composantes (dimensions/outliers) dans les sorties des couches peuvent avoir un effet disproportionn√© sur le mod√®le, ce qui invite √† surveiller et r√©guler les facteurs d\\'√©chelle. Contr√¥ler LayerNorm et les dimensions anormales est donc une voie cl√© pour la robustesse et l\\'efficience. [Paper 2, Paper 4]\\n\\n‚Ä¢ Les innovations r√©centes ciblent la perte progressive de capacit√© repr√©sentative de la matrice d\\'attention √† travers les couches ; des m√©canismes qui r√©cup√®rent l\\'information r√©siduelle n√©glig√©e (par ex. ¬´ Twicing ¬ª) am√©liorent la richesse des repr√©sentations et la performance sans changer radicalement la famille Transformer. Ces apports montrent comment redistribuer ou r√©injecter l\\'information r√©siduelle peut restaurer la puissance d\\'expression du r√©seau. [Paper 3]\\n\\n‚Ä¢ En parall√®le des am√©liorations internes des Transformers, des approches architecturales alternatives ou hybrides cherchent √† gagner en vitesse et en co√ªt (p. ex. encodeurs convolutionnels pour l\\'extraction de relations). Ces solutions d√©montrent un compromis pratique : conserver des blocs Transformer l√† o√π leur expressivit√© est cruciale et remplacer ou all√©ger d\\'autres parties pour l\\'efficacit√© √† grande √©chelle. [Paper 5, Paper 3]\\n\\n## R√©f√©rences\\n[Paper 1] Exploring the Impact of Layer Normalization for Zero-shot Neural Machine Translation - Zhuoyuan Mao, Raj Dabre, Qianying Liu (2023-05-16) - http://arxiv.org/abs/2305.09312v1\\n\\n[Paper 2] LayerNorm: A key component in parameter-efficient fine-tuning - Taha ValizadehAslani, Hualou Liang (2024-03-29) - http://arxiv.org/abs/2403.20284v1\\n\\n[Paper 3] Transformer Meets Twicing: Harnessing Unattended Residual Information - Laziz Abdullaev, Tan M. Nguyen (2025-03-02) - http://arxiv.org/abs/2503.00687v3\\n\\n[Paper 4] BERT Busters: Outlier Dimensions that Disrupt Transformers - Olga Kovaleva, Saurabh Kulshreshtha, Anna Rogers (2021-05-14) - http://arxiv.org/abs/2105.06990v2\\n\\n[Paper 5] FastRE: Towards Fast Relation Extraction with Convolutional Encoder and Improved Cascade Binary Tagging Framework - Guozheng Li, Xu Chen, Peng Wang (2022-05-05) - http://arxiv.org/abs/2205.02490v2', additional_kwargs={}, response_metadata={}, name='Summarizer')]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Configuration for this run (needed for memory/checkpointing)\n",
    "config = {\"configurable\": {\"thread_id\": \"demo-thread-1\"}}\n",
    "\n",
    "question = \"What are the key innovations in transformer architectures?\"\n",
    "\n",
    "# Only provide required fields + config\n",
    "initial_state = {\n",
    "    \"query\": question,\n",
    "    \"config\": {\n",
    "        \"llm_model\": LLM_MODEL,\n",
    "        \"llm_temperature\": 0,\n",
    "        \"max_papers\": 5,\n",
    "        \"max_iterations\": 2,\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Starting agent graph execution...\\n\")\n",
    "\n",
    "# Invoke the graph\n",
    "result = graph.invoke(initial_state, config=config)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8117bbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL RESULT\n",
      "================================================================================\n",
      "\n",
      "- Original query: What are the key innovations in transformer architectures?\n",
      "- Refined query: transformer innovations self-attention multi-head positional encodings residual connections layernorm\n",
      "- Papers found: 5\n",
      "- Iterations: 1\n",
      "\n",
      "## R√©sum√©\n",
      "‚Ä¢ Le positionnement et le comportement de la normalisation de couche (LayerNorm) dans les blocs Transformer influencent fortement la stabilit√© d'entra√Ænement et la g√©n√©ralisation en traduction z√©ro-shot. Des configurations \"PreNorm\" courantes peuvent acc√©l√©rer la convergence mais risquent de suradapter les donn√©es d'entra√Ænement, d'o√π l'int√©r√™t d'√©tudier et d'ajuster cette composante pour de meilleures performances ZST. Ces choix de normalisation interagissent aussi avec d'autres changements d'architecture. [Paper 1, Paper 2]\n",
      "\n",
      "‚Ä¢ LayerNorm s'av√®re √™tre un levier central pour les m√©thodes de fine-tuning √† param√®tres efficaces : modifier ou geler ses param√®tres permet de r√©duire le co√ªt d'adaptation tout en conservant des performances solides. Parall√®lement, certains travaux montrent que de tr√®s petites composantes (dimensions/outliers) dans les sorties des couches peuvent avoir un effet disproportionn√© sur le mod√®le, ce qui invite √† surveiller et r√©guler les facteurs d'√©chelle. Contr√¥ler LayerNorm et les dimensions anormales est donc une voie cl√© pour la robustesse et l'efficience. [Paper 2, Paper 4]\n",
      "\n",
      "‚Ä¢ Les innovations r√©centes ciblent la perte progressive de capacit√© repr√©sentative de la matrice d'attention √† travers les couches ; des m√©canismes qui r√©cup√®rent l'information r√©siduelle n√©glig√©e (par ex. ¬´ Twicing ¬ª) am√©liorent la richesse des repr√©sentations et la performance sans changer radicalement la famille Transformer. Ces apports montrent comment redistribuer ou r√©injecter l'information r√©siduelle peut restaurer la puissance d'expression du r√©seau. [Paper 3]\n",
      "\n",
      "‚Ä¢ En parall√®le des am√©liorations internes des Transformers, des approches architecturales alternatives ou hybrides cherchent √† gagner en vitesse et en co√ªt (p. ex. encodeurs convolutionnels pour l'extraction de relations). Ces solutions d√©montrent un compromis pratique : conserver des blocs Transformer l√† o√π leur expressivit√© est cruciale et remplacer ou all√©ger d'autres parties pour l'efficacit√© √† grande √©chelle. [Paper 5, Paper 3]\n",
      "\n",
      "## R√©f√©rences\n",
      "[Paper 1] Exploring the Impact of Layer Normalization for Zero-shot Neural Machine Translation - Zhuoyuan Mao, Raj Dabre, Qianying Liu (2023-05-16) - http://arxiv.org/abs/2305.09312v1\n",
      "\n",
      "[Paper 2] LayerNorm: A key component in parameter-efficient fine-tuning - Taha ValizadehAslani, Hualou Liang (2024-03-29) - http://arxiv.org/abs/2403.20284v1\n",
      "\n",
      "[Paper 3] Transformer Meets Twicing: Harnessing Unattended Residual Information - Laziz Abdullaev, Tan M. Nguyen (2025-03-02) - http://arxiv.org/abs/2503.00687v3\n",
      "\n",
      "[Paper 4] BERT Busters: Outlier Dimensions that Disrupt Transformers - Olga Kovaleva, Saurabh Kulshreshtha, Anna Rogers (2021-05-14) - http://arxiv.org/abs/2105.06990v2\n",
      "\n",
      "[Paper 5] FastRE: Towards Fast Relation Extraction with Convolutional Encoder and Improved Cascade Binary Tagging Framework - Guozheng Li, Xu Chen, Peng Wang (2022-05-05) - http://arxiv.org/abs/2205.02490v2\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n- Original query: {result['query']}\")\n",
    "print(f\"- Refined query: {result['refined_query']}\")\n",
    "print(f\"- Papers found: {len(result['papers'])}\")\n",
    "print(f\"- Iterations: {result['iteration']}\")\n",
    "print(f\"\\n{result['summary']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aa35b6",
   "metadata": {},
   "source": [
    "### Test 2: Query with Few Results (Triggers Loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d83bf138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting agent graph execution...\n",
      "\n",
      "üéØ Clarifying query: 'quantum machine learning for protein folding using NISQ devices'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 17:56:50,186 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-21 17:56:50,195 - INFO - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=NISQ+variational+quantum+algorithms+protein+folding&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ú® Refined query: 'NISQ variational quantum algorithms protein folding'\n",
      "üîç Searching ArXiv: 'NISQ variational quantum algorithms protein folding' (iteration 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 17:56:51,175 - INFO - Got first page: 100 of 835056 total results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Found 5 papers\n",
      "üìù Synthesizing 5 papers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 17:57:14,021 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Summary generated\n",
      "\n",
      "================================================================================\n",
      "FINAL RESULT\n",
      "================================================================================\n",
      "\n",
      "- Original query: quantum machine learning for protein folding using NISQ devices\n",
      "- Refined query: NISQ variational quantum algorithms protein folding\n",
      "- Papers found: 5\n",
      "- Iterations: 2\n",
      "\n",
      "## R√©sum√©\n",
      "‚Ä¢ NISQ-oriented algorithms adapt protein folding to near-term gate-based devices by using hybrid classical‚Äìquantum workflows and compressed evolutions (digitized counterdiabatic, variational ans√§tze). These approaches aim to reduce circuit depth and runtime while keeping the search for low-energy conformations feasible on limited hardware [Paper 1, Paper 2].  \n",
      "‚Ä¢ Problem encoding and lattice models are central: mapping amino-acid chains to lattice representations (cubic, tetrahedral) and compact encodings markedly lowers qubit and gate counts, at the cost of model fidelity. Efficient encodings also enable exploring free-energy landscapes more directly on quantum hardware [Paper 3, Paper 4].  \n",
      "‚Ä¢ Variational and QAOA-like methods (including alternating‚Äëoperator ans√§tze) have shown promising numerical results for small peptides, demonstrating that approximate ground states and conformational sampling can be obtained on simulators and small devices. However, these studies repeatedly report scaling and noise-sensitivity challenges for larger proteins [Paper 5, Paper 3].  \n",
      "‚Ä¢ Resource-analysis and algorithmic compression (e.g., digitized‚Äëcounterdiabatic schemes and other resource‚Äëefficient designs) indicate realistic near‚Äëterm targets: small to medium peptides, hybrid optimization loops, and extensive classical preprocessing/postprocessing remain necessary. Continued improvements in error mitigation, encoding, and hardware will be required before tackling biologically sized folding problems [Paper 2, Paper 1, Paper 5, Paper 4].\n",
      "\n",
      "## R√©f√©rences\n",
      "[Paper 1] Digitized-Counterdiabatic Quantum Algorithm for Protein Folding - Pranav Chandarana, Narendra N. Hegade, Iraitz Montalban (2022) - http://arxiv.org/abs/2212.13511v1\n",
      "\n",
      "[Paper 2] Resource-Efficient Quantum Algorithm for Protein Folding - Anton Robert, Panagiotis Kl. Barkoutsos, Stefan Woerner (2019) - http://arxiv.org/abs/1908.02163v1\n",
      "\n",
      "[Paper 3] A quantum alternating operator ansatz with hard and soft constraints for lattice protein folding - Mark Fingerhuth, Tom√°≈° Babej, Christopher Ing (2018) - http://arxiv.org/abs/1810.13411v1\n",
      "\n",
      "[Paper 4] Capturing Protein Free Energy Landscape using Efficient Quantum Encoding - Ashwini Kannan, Jaya Vasavi Pamidimukkala, Avinash Dakshinamoorthy (2025) - http://arxiv.org/abs/2510.15316v1\n",
      "\n",
      "[Paper 5] Peptide conformational sampling using the Quantum Approximate Optimization Algorithm - Sami Boulebnane, Xavier Lucas, Agnes Meyder (2022) - http://arxiv.org/abs/2204.01821v1\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Configuration for this run (needed for memory/checkpointing)\n",
    "config = {\"configurable\": {\"thread_id\": \"demo-thread-1\"}}\n",
    "\n",
    "question = \"quantum machine learning for protein folding using NISQ devices\"\n",
    "\n",
    "initial_state = {\n",
    "    \"query\": question,\n",
    "    \"config\": {\n",
    "        \"llm_model\": LLM_MODEL,\n",
    "        \"llm_temperature\": 0,\n",
    "        \"max_papers\": 5,\n",
    "        \"max_iterations\": 2,\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Starting agent graph execution...\\n\")\n",
    "\n",
    "# Invoke the graph\n",
    "result = graph.invoke(initial_state, config=config)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n- Original query: {result['query']}\")\n",
    "print(f\"- Refined query: {result['refined_query']}\")\n",
    "print(f\"- Papers found: {len(result['papers'])}\")\n",
    "print(f\"- Iterations: {result['iteration']}\")\n",
    "print(f\"\\n{result['summary']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798810c8",
   "metadata": {},
   "source": [
    "### Test 3: Memory Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a45cc2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Clarifying query: 'Explain attention mechanisms'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 17:57:20,220 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-21 17:57:20,226 - INFO - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=attention+mechanisms+in+neural+networks+review&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ú® Refined query: 'attention mechanisms in neural networks review'\n",
      "üîç Searching ArXiv: 'attention mechanisms in neural networks review' (iteration 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 17:57:21,480 - INFO - Got first page: 100 of 2705421 total results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Found 5 papers\n",
      "üìù Synthesizing 5 papers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 17:57:45,685 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Summary generated\n",
      "‚úÖ First query completed - 4 messages in memory\n",
      "üéØ Clarifying query: 'What about self-attention?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 17:57:51,946 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-10-21 17:57:51,955 - INFO - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=self-attention+mechanisms+in+transformers&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ú® Refined query: 'self-attention mechanisms in transformers'\n",
      "üîç Searching ArXiv: 'self-attention mechanisms in transformers' (iteration 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 17:57:53,036 - INFO - Got first page: 100 of 2695572 total results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Found 5 papers\n",
      "üìù Synthesizing 5 papers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 17:58:17,979 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Summary generated\n",
      "‚úÖ Second query completed - 8 messages in memory\n",
      "\n",
      "üìú Message History:\n",
      "  1. [AIMessage] Summarizer: ## R√©sum√©\n",
      "‚Ä¢ Attention is a mechanism that selects and differentially weights parts of an input so a ...\n",
      "  2. [HumanMessage] User: What about self-attention?\n",
      "  3. [AIMessage] Clarifier: Refined query: self-attention mechanisms in transformers\n",
      "  4. [AIMessage] Researcher: Found 5 papers on ArXiv for query: self-attention mechanisms in transformers\n",
      "  5. [AIMessage] Summarizer: ## R√©sum√©\n",
      "‚Ä¢ Self-attention emerges from a more general principle of learned pairwise affinity matric...\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"demo-thread-3\"}}\n",
    "\n",
    "# First query\n",
    "question1 = \"Explain attention mechanisms\"\n",
    "result1 = graph.invoke({\n",
    "    \"query\": question1,\n",
    "    \"config\": {\n",
    "        \"llm_model\": LLM_MODEL,\n",
    "        \"llm_temperature\": 0,\n",
    "        \"max_papers\": 5,\n",
    "        \"max_iterations\": 2,\n",
    "    }\n",
    "}, config=config)\n",
    "\n",
    "print(f\"‚úÖ First query completed - {len(result1['messages'])} messages in memory\")\n",
    "\n",
    "# Second query (same thread, memory persists automatically via checkpointer)\n",
    "question2 = \"What about self-attention?\"\n",
    "result2 = graph.invoke({\n",
    "    \"query\": question2,\n",
    "    \"config\": {\n",
    "        \"llm_model\": LLM_MODEL,\n",
    "        \"llm_temperature\": 0,\n",
    "        \"max_papers\": 5,\n",
    "        \"max_iterations\": 2,\n",
    "    }\n",
    "}, config=config)\n",
    "\n",
    "print(f\"‚úÖ Second query completed - {len(result2['messages'])} messages in memory\")\n",
    "\n",
    "# Display message history\n",
    "print(\"\\nüìú Message History:\")\n",
    "for i, msg in enumerate(result2['messages'][-5:], 1):  # Show last 5 messages\n",
    "    msg_type = msg.__class__.__name__\n",
    "    name = getattr(msg, 'name', 'Unknown')\n",
    "    content_preview = msg.content[:100] + \"...\" if len(msg.content) > 80 else msg.content\n",
    "    print(f\"  {i}. [{msg_type}] {name}: {content_preview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d547b2a3",
   "metadata": {},
   "source": [
    "### View Results in LangSmith Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f8c1c2",
   "metadata": {},
   "source": [
    "### Option 1: View Past Runs (Tracing)\n",
    "\n",
    "If you have `LANGCHAIN_TRACING_V2=true` in your `.env`:\n",
    "1. Go to https://smith.langchain.com\n",
    "2. Navigate to your project (e.g., \"scientific-graph-agent\")\n",
    "3. Click on any run to see:\n",
    "   - Full execution trace\n",
    "   - Each node's input/output\n",
    "   - LLM calls and tokens used\n",
    "   - Execution time per node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668b2471",
   "metadata": {},
   "source": [
    "### Option 2: Interactive Studio (Live Development)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1156049a",
   "metadata": {},
   "source": [
    "To interact with your graph in real-time:\n",
    "\n",
    "```bash\n",
    "# In your terminal, run:\n",
    "langgraph dev\n",
    "\n",
    "# This will open in browser:\n",
    "# https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "```\n",
    "\n",
    "The Studio provides:\n",
    "- **Visual graph editor** - See your nodes and edges\n",
    "- **Interactive chat** - Test queries in real-time\n",
    "- **State inspector** - View state after each node\n",
    "- **Thread history** - Browse past conversations by thread_id\n",
    "- **Debugger** - Step through execution node by node\n",
    "\n",
    "**Quick Setup for Studio:**\n",
    "\n",
    "1. Ensure `langgraph.json` exists in project root\n",
    "2. Start the server: `langgraph dev`\n",
    "3. Open https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "4. Click \"New Thread\" and type your question\n",
    "5. Watch the graph execute in real-time!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scientific-graph-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
