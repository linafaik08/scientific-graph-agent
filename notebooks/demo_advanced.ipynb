{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e7de14f",
   "metadata": {},
   "source": [
    "# üß™ Scientific Graph Agent - Advanced Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e943173",
   "metadata": {},
   "source": [
    "This notebook demonstrates **advanced LangGraph features**: streaming, interrupts (human-in-the-loop), and time travel (state rewinding/branching).\n",
    "\n",
    "**Prerequisites**: Familiarity with basic LangGraph concepts (nodes, edges, state). See `demo_basic.ipynb` for fundamentals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e2a928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Reduce logging noise for cleaner output\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "# Auto-reload modules when they change (useful during development)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ced08c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_MODEL = \"gpt-5-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa1950f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment variables loaded\n"
     ]
    }
   ],
   "source": [
    "# Verify that API keys are set\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"‚ö†Ô∏è  OPENAI_API_KEY not found in .env file\")\n",
    "\n",
    "print(\"‚úÖ Environment variables loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be7942fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/linafaik/Documents/projects/scientific-graph-agent\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc756288",
   "metadata": {},
   "source": [
    "## Graph Initialization\n",
    "\n",
    "**Key concept**: `with_checkpointer=True` enables **persistence** - the graph saves state snapshots after each node.\n",
    "\n",
    "This is required for:\n",
    "- üî¥ **Interrupts** (pausing/resuming execution)\n",
    "- ‚è™ **Time travel** (accessing historical states)\n",
    "- üîÑ **Multi-turn conversations** (maintaining context across runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e7e4d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:14:06,128 - INFO - ‚úÖ Streaming graph compiled with async memory enabled\n"
     ]
    }
   ],
   "source": [
    "from src.agent_graph.graph import create_streaming_graph\n",
    "\n",
    "# Create graph with async support for streaming\n",
    "# with_checkpointer=True ‚Üí Enables persistence for interrupts/time-travel\n",
    "streaming_graph = await create_streaming_graph(with_checkpointer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a01e19",
   "metadata": {},
   "source": [
    "### Graph Visualization\n",
    "\n",
    "Our agent graph has **conditional edges** that create a loop:\n",
    "- `clarifier` ‚Üí `researcher` ‚Üí `summarizer` ‚Üí END\n",
    "- If not enough papers, `summarizer` ‚Üí `clarifier` (retry with refined query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1e2eae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph structure:\n",
      "START ‚Üí clarifier ‚Üí researcher ‚Üí summarizer ‚Üí END\n",
      "           ‚Üë            ‚Üì\n",
      "           ‚îî‚îÄ(if <3 papers)\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "    \n",
    "# Generate graph visualization as PNG\n",
    "display(Image(streaming_graph.get_graph().draw_mermaid_png()))\n",
    "print(\"Graph structure:\")\n",
    "print(\"START ‚Üí clarifier ‚Üí researcher ‚Üí summarizer ‚Üí END\")\n",
    "print(\"           ‚Üë            ‚Üì\")\n",
    "print(\"           ‚îî‚îÄ(if <3 papers)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6c4a87",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "**LangGraph streaming modes** provide different granularities of real-time updates:\n",
    "\n",
    "| Mode | What it shows | Use case |\n",
    "|------|---------------|----------|\n",
    "| `\"messages\"` | **Token-level** LLM output as it's generated | Typewriter effect, real-time LLM thinking |\n",
    "| `\"updates\"` | **Node-level** state changes after each node completes | Track agent progress, debug workflow |\n",
    "| `\"custom\"` | **Tool progress** custom messages from tools | ArXiv search progress, file operations |\n",
    "\n",
    "You can **combine multiple modes** in a single stream for complete visibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ppuwav7pen",
   "metadata": {},
   "source": [
    "### Test 1: Token-Level Streaming (`stream_mode=\"messages\"`)\n",
    "\n",
    "**What**: Stream individual tokens as the LLM generates them (typewriter effect).\n",
    "\n",
    "**How**: Each chunk is a tuple `(message, metadata)` where:\n",
    "- `message.content` contains the token(s)\n",
    "- `metadata[\"langgraph_node\"]` tells you which node emitted it\n",
    "\n",
    "**When to use**: Show live LLM output, create interactive UIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f5d65c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:17:04,749 - INFO - Clarifying query: 'What is attention mechanism in transformers?'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Watching LLM token generation in real-time...\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:17:08,259 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:17:08,336 - INFO - Refined query: 'Transformer self-attention scaled dot-product query key value'\n",
      "2025-11-16 12:17:09,970 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:17:09,997 - INFO - üîç Searching ArXiv: 'Transformer self-attention scaled dot-product query key value' (iteration 0)\n",
      "2025-11-16 12:17:10,621 - INFO - Found 3 papers\n",
      "2025-11-16 12:17:10,622 - INFO - Scoring paper relevance...\n",
      "2025-11-16 12:17:10,629 - INFO -   üìÑ Attention Guided CAM: Visual Explanations of Vision Transfor... - Score: 60\n",
      "2025-11-16 12:17:10,633 - INFO -   üìÑ Primal-Attention: Self-attention through Asymmetric Kernel S... - Score: 92\n",
      "2025-11-16 12:17:10,636 - INFO -   üìÑ Toward Interpretable Music Tagging with Self-Attention... - Score: 75\n",
      "2025-11-16 12:17:12,384 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:17:12,391 - INFO - üìù Synthesizing 4 papers with streaming...\n",
      "2025-11-16 12:17:26,476 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù SUMMARIZER (streaming tokens):\n",
      "--------------------------------------------------------------------------------\n",
      "## R√©sum√©\n",
      "‚Ä¢ Attention in transformers is an operation that computes, for each position, a weighted sum of value vectors where weights come from compatibility between a query and keys ‚Äî in practice implemented as self-attention that relates different sequence positions to build contextualized representations [Paper 1, Paper 2].  \n",
      "‚Ä¢ In Transformer architectures (including Vision Transformers), attention replaces recurrence/convolution: multi‚Äëhead scaled dot‚Äëproduct attention lets the model attend to multiple types of relations in parallel and capture long‚Äërange dependencies in a single layer [Paper 2, Paper 3].  \n",
      "‚Ä¢ Researchers analyze and improve attention both practically and theoretically: kernel and linear‚Äëalgebra views (e.g., asymmetric kernel SVD) aim to explain and make self‚Äëattention more efficient or interpretable, while task‚Äëspecific studies probe how attention maps relate to semantic cues in music and vision [Paper 1, Paper 2, Paper 3].  \n",
      "‚Ä¢ Attention is widely useful but not always the only solution for sequence or video tasks ‚Äî some applications still use classical feature methods (e.g., entropy‚Äëbased key‚Äëframe extraction) or hybrid pipelines that combine attention with other techniques depending on compute and data needs [Paper 3, Paper 4].\n",
      "\n",
      "## R√©f√©rences\n",
      "[Paper 1] Primal-Attention: Self-attention through Asymmetric Kernel SVD in Primal Representation - Yingyi Chen, Qinghua Tao, Francesco Tonin (2023) - http://arxiv.org/abs/2305.19798v2\n",
      "\n",
      "[Paper 2] Toward Interpretable Music Tagging with Self-Attention - Minz Won, Sanghyuk Chun, Xavier Serra (2019) - http://arxiv.org/abs/1906.04972v1\n",
      "\n",
      "[Paper 3] Attention Guided CAM: Visual Explanations of Vision Transformer Guided by Self-Attention - Saebom Leem, Hyunseok Seo (2024) - http://arxiv.org/abs/2402.04563v1\n",
      "\n",
      "[Paper 4] Video Key Frame Extraction using Entropy value as Global and Local Feature - Siddu P Algur, Vivek R (2016) - http://arxiv.org/abs/1605.08857v1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:17:32,952 - INFO - ‚úÖ Summary generated\n",
      "2025-11-16 12:17:36,330 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## R√©sum√©\n",
      "‚Ä¢ Attention in transformers is an operation that computes, for each position, a weighted sum of value vectors where weights come from compatibility between a query and keys ‚Äî in practice implemented as self-attention that relates different sequence positions to build contextualized representations [Paper 1, Paper 2].  \n",
      "‚Ä¢ In Transformer architectures (including Vision Transformers), attention replaces recurrence/convolution: multi‚Äëhead scaled dot‚Äëproduct attention lets the model attend to multiple types of relations in parallel and capture long‚Äërange dependencies in a single layer [Paper 2, Paper 3].  \n",
      "‚Ä¢ Researchers analyze and improve attention both practically and theoretically: kernel and linear‚Äëalgebra views (e.g., asymmetric kernel SVD) aim to explain and make self‚Äëattention more efficient or interpretable, while task‚Äëspecific studies probe how attention maps relate to semantic cues in music and vision [Paper 1, Paper 2, Paper 3].  \n",
      "‚Ä¢ Attention is widely useful but not always the only solution for sequence or video tasks ‚Äî some applications still use classical feature methods (e.g., entropy‚Äëbased key‚Äëframe extraction) or hybrid pipelines that combine attention with other techniques depending on compute and data needs [Paper 3, Paper 4].\n",
      "\n",
      "## R√©f√©rences\n",
      "[Paper 1] Primal-Attention: Self-attention through Asymmetric Kernel SVD in Primal Representation - Yingyi Chen, Qinghua Tao, Francesco Tonin (2023) - http://arxiv.org/abs/2305.19798v2\n",
      "\n",
      "[Paper 2] Toward Interpretable Music Tagging with Self-Attention - Minz Won, Sanghyuk Chun, Xavier Serra (2019) - http://arxiv.org/abs/1906.04972v1\n",
      "\n",
      "[Paper 3] Attention Guided CAM: Visual Explanations of Vision Transformer Guided by Self-Attention - Saebom Leem, Hyunseok Seo (2024) - http://arxiv.org/abs/2402.04563v1\n",
      "\n",
      "[Paper 4] Video Key Frame Extraction using Entropy value as Global and Local Feature - Siddu P Algur, Vivek R (2016) - http://arxiv.org/abs/1605.08857v1\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Token streaming complete!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Thread ID tracks conversation history (checkpoints are stored per thread)\n",
    "config_token = {\"configurable\": {\"thread_id\": \"demo-stream-4\"}}\n",
    "\n",
    "question = \"What is attention mechanism in transformers?\"\n",
    "\n",
    "initial_state = {\n",
    "    \"query\": question,\n",
    "    \"llm_model\": LLM_MODEL,\n",
    "    \"llm_temperature\": 0,\n",
    "    \"max_papers\": 3,\n",
    "    \"max_iterations\": 2,\n",
    "}\n",
    "\n",
    "print(\"üöÄ Watching LLM token generation in real-time...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "in_summarizer = False\n",
    "\n",
    "# stream_mode=\"messages\" ‚Üí Get token-level chunks as LLM generates\n",
    "async for chunk in streaming_graph.astream(\n",
    "    initial_state,\n",
    "    config=config_token,\n",
    "    stream_mode=\"messages\"  # Each chunk = (message, metadata)\n",
    "):\n",
    "    message, metadata = chunk\n",
    "    \n",
    "    # Filter to only show summarizer node output\n",
    "    node_name = metadata.get(\"langgraph_node\", \"\")\n",
    "    \n",
    "    if node_name == \"summarizer\":\n",
    "        if not in_summarizer:\n",
    "            print(\"\\nüìù SUMMARIZER (streaming tokens):\")\n",
    "            print(\"-\" * 80)\n",
    "            in_summarizer = True\n",
    "        \n",
    "        # Print tokens as they arrive (creates typewriter effect)\n",
    "        if hasattr(message, 'content') and message.content:\n",
    "            print(message.content, end='', flush=True)\n",
    "    elif in_summarizer and node_name != \"summarizer\":\n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        in_summarizer = False\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\n‚úÖ Token streaming complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcixt2emvp",
   "metadata": {},
   "source": [
    "### Test 2: Node-Level Streaming (`stream_mode=\"updates\"`)\n",
    "\n",
    "**What**: Get state updates after each node completes.\n",
    "\n",
    "**How**: Each event is a dict `{node_name: state_update}` containing only the fields that changed.\n",
    "\n",
    "**When to use**: Track workflow progress, show which step is running, debug state flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "j75dwyqidcg",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:18:39,282 - INFO - Clarifying query: 'What are recent advances in graph neural networks?'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting graph with agent progress streaming...\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:18:46,318 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:18:46,334 - INFO - Refined query: 'graph neural networks recent advances survey 2022-2025'\n",
      "2025-11-16 12:18:50,289 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:18:50,300 - INFO - üîç Searching ArXiv: 'graph neural networks recent advances survey 2022-2025' (iteration 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìç Node: clarifier\n",
      "--------------------------------------------------------------------------------\n",
      "  ‚ú® Refined query: graph neural networks recent advances survey 2022-2025\n",
      "  üîÑ Iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:18:51,094 - INFO - Found 3 papers\n",
      "2025-11-16 12:18:51,095 - INFO - Scoring paper relevance...\n",
      "2025-11-16 12:18:51,101 - INFO -   üìÑ The Deep Arbitrary Polynomial Chaos Neural Network or how De... - Score: 10\n",
      "2025-11-16 12:18:51,104 - INFO -   üìÑ A Review on Neural Network Models of Schizophrenia and Autis... - Score: 5\n",
      "2025-11-16 12:18:51,107 - INFO -   üìÑ Learning Active Subspaces and Discovering Important Features... - Score: 3\n",
      "2025-11-16 12:18:52,826 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:18:52,845 - INFO - üìù Synthesizing 3 papers with streaming...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìç Node: researcher\n",
      "--------------------------------------------------------------------------------\n",
      "  üìö Papers found: 3\n",
      "     1. The Deep Arbitrary Polynomial Chaos Neural Network or how De... (Score: 10)\n",
      "     2. A Review on Neural Network Models of Schizophrenia and Autis... (Score: 5)\n",
      "     3. Learning Active Subspaces and Discovering Important Features... (Score: 3)\n",
      "  üîÑ Iteration: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:19:09,460 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:19:16,924 - INFO - ‚úÖ Summary generated\n",
      "2025-11-16 12:19:18,992 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìç Node: summarizer\n",
      "--------------------------------------------------------------------------------\n",
      "  üìù Summary preview: ## R√©sum√©\n",
      "‚Ä¢ The three provided papers do not study graph neural networks directly; they report advances in different neural‚Äënetwork subfields (data‚Äëdr...\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Streaming complete!\n"
     ]
    }
   ],
   "source": [
    "config_stream = {\"configurable\": {\"thread_id\": \"demo-stream-1\"}}\n",
    "\n",
    "question = \"What are recent advances in graph neural networks?\"\n",
    "\n",
    "initial_state = {\n",
    "    \"query\": question,\n",
    "    \"llm_model\": LLM_MODEL,\n",
    "    \"llm_temperature\": 0,\n",
    "    \"max_papers\": 3,\n",
    "    \"max_iterations\": 2,\n",
    "}\n",
    "\n",
    "print(\"üöÄ Starting graph with agent progress streaming...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# stream_mode=\"updates\" ‚Üí Get state changes after each node\n",
    "async for event in streaming_graph.astream(\n",
    "    initial_state,\n",
    "    config=config_stream,\n",
    "    stream_mode=\"updates\"  # event = {node_name: state_update}\n",
    "):\n",
    "    for node_name, state_update in event.items():\n",
    "        print(f\"\\nüìç Node: {node_name}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Show key state changes (only modified fields are included)\n",
    "        if \"refined_query\" in state_update:\n",
    "            print(f\"  ‚ú® Refined query: {state_update['refined_query']}\")\n",
    "        \n",
    "        if \"papers\" in state_update:\n",
    "            papers = state_update[\"papers\"]\n",
    "            print(f\"  üìö Papers found: {len(papers)}\")\n",
    "            for i, paper in enumerate(papers, 1):\n",
    "                score = paper.get('relevance_score', 'N/A')\n",
    "                print(f\"     {i}. {paper['title'][:60]}... (Score: {score})\")\n",
    "        \n",
    "        if \"summary\" in state_update and state_update[\"summary\"] != \"NEED_MORE_PAPERS\":\n",
    "            summary = state_update[\"summary\"]\n",
    "            print(f\"  üìù Summary preview: {summary[:150]}...\")\n",
    "        \n",
    "        if \"iteration\" in state_update:\n",
    "            print(f\"  üîÑ Iteration: {state_update['iteration']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Streaming complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "znjrp0op2w",
   "metadata": {},
   "source": [
    "### Test 3: Custom Progress Streaming (`stream_mode=\"custom\"`)\n",
    "\n",
    "**What**: Custom progress messages emitted by tools using `writer.write()`.\n",
    "\n",
    "**How**: Tools can send progress updates (e.g., \"Found 3/5 papers...\") during execution.\n",
    "\n",
    "**When to use**: Long-running operations, show fine-grained tool progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8k9l9zggxm",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:20:10,751 - INFO - Clarifying query: 'Explain vision transformers'\n",
      "2025-11-16 12:20:10,758 - INFO - Refined query: 'Vision Transformer ViT architecture self-attention patch embeddings'\n",
      "2025-11-16 12:20:10,759 - INFO - üîç Searching ArXiv: 'Vision Transformer ViT architecture self-attention patch embeddings' (iteration 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting graph with custom progress streaming...\n",
      "\n",
      "================================================================================\n",
      "  Starting ArXiv search for: 'Vision Transformer ViT architecture self-attention patch embeddings'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:20:11,430 - INFO - Found 5 papers\n",
      "2025-11-16 12:20:11,430 - INFO - Scoring paper relevance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found paper 1/5: Attention Guided CAM: Visual Explanations of Vision Transfor...\n",
      "  Found paper 2/5: Evo-ViT: Slow-Fast Token Evolution for Dynamic Vision Transf...\n",
      "  Found paper 3/5: Jigsaw-ViT: Learning Jigsaw Puzzles in Vision Transformer...\n",
      "  Found paper 4/5: Tokens-to-Token ViT: Training Vision Transformers from Scrat...\n",
      "  Found paper 5/5: V2X-ViT: Vehicle-to-Everything Cooperative Perception with V...\n",
      "  ‚úÖ Search complete: 5 papers found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:20:14,748 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:20:14,755 - INFO -   üìÑ Attention Guided CAM: Visual Explanations of Vision Transfor... - Score: 75\n",
      "2025-11-16 12:20:19,237 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:20:19,249 - INFO -   üìÑ Evo-ViT: Slow-Fast Token Evolution for Dynamic Vision Transf... - Score: 65\n",
      "2025-11-16 12:20:22,995 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:20:23,005 - INFO -   üìÑ Jigsaw-ViT: Learning Jigsaw Puzzles in Vision Transformer... - Score: 75\n",
      "2025-11-16 12:20:25,897 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:20:25,908 - INFO -   üìÑ Tokens-to-Token ViT: Training Vision Transformers from Scrat... - Score: 92\n",
      "2025-11-16 12:20:28,911 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:20:28,923 - INFO -   üìÑ V2X-ViT: Vehicle-to-Everything Cooperative Perception with V... - Score: 60\n",
      "2025-11-16 12:20:28,927 - INFO - üìù Synthesizing 5 papers with streaming...\n",
      "2025-11-16 12:20:44,944 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:20:56,368 - INFO - ‚úÖ Summary generated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "‚úÖ Custom streaming complete!\n"
     ]
    }
   ],
   "source": [
    "config_custom = {\"configurable\": {\"thread_id\": \"demo-stream-2\"}}\n",
    "\n",
    "question = \"Explain vision transformers\"\n",
    "\n",
    "initial_state = {\n",
    "    \"query\": question,\n",
    "    \"llm_model\": LLM_MODEL,\n",
    "    \"llm_temperature\": 0,\n",
    "    \"max_papers\": 5,\n",
    "    \"max_iterations\": 2,\n",
    "}\n",
    "\n",
    "print(\"üöÄ Starting graph with custom progress streaming...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# stream_mode=\"custom\" ‚Üí Get custom progress messages from tools\n",
    "# (requires tools to use `writer.write(message)` to emit updates)\n",
    "async for event in streaming_graph.astream(\n",
    "    initial_state,\n",
    "    config=config_custom,\n",
    "    stream_mode=\"custom\"\n",
    "):\n",
    "    # Custom events are the raw messages emitted by tools\n",
    "    print(f\"  {event}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Custom streaming complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ym3n9m0u4ok",
   "metadata": {},
   "source": [
    "### Test 4: Multi-Mode Streaming (Combined)\n",
    "\n",
    "**What**: Combine multiple streaming modes for complete visibility.\n",
    "\n",
    "**How**: Pass a list `[\"updates\", \"messages\", \"custom\"]` and each event becomes a tuple `(mode, data)`.\n",
    "\n",
    "**When to use**: Debugging, building rich UIs with multiple feedback layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2p3cg27k37x",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:21:40,981 - INFO - Clarifying query: 'What is few-shot learning?'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting graph with multi-mode streaming...\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:21:46,865 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:21:47,019 - INFO - Refined query: 'few-shot learning survey definition meta-learning metric-learning'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî∑ NODE UPDATE: clarifier\n",
      "   ‚ú® Refined query: few-shot learning survey definition meta-learning metric-learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:21:48,251 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:21:48,256 - INFO - üîç Searching ArXiv: 'few-shot learning survey definition meta-learning metric-learning' (iteration 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî∂ PROGRESS: Starting ArXiv search for: 'few-shot learning survey definition meta-learning metric-learning'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:21:49,100 - INFO - Found 3 papers\n",
      "2025-11-16 12:21:49,101 - INFO - Scoring paper relevance...\n",
      "2025-11-16 12:21:49,110 - INFO -   üìÑ Few-shot Learning with Meta Metric Learners... - Score: 90\n",
      "2025-11-16 12:21:49,115 - INFO -   üìÑ Regression Networks for Meta-Learning Few-Shot Classificatio... - Score: 90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî∂ PROGRESS: Found paper 1/3: Few-shot Learning with Meta Metric Learners...\n",
      "üî∂ PROGRESS: Found paper 2/3: Regression Networks for Meta-Learning Few-Shot Classificatio...\n",
      "üî∂ PROGRESS: Found paper 3/3: Meta-Baseline: Exploring Simple Meta-Learning for Few-Shot L...\n",
      "üî∂ PROGRESS: ‚úÖ Search complete: 3 papers found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:21:52,036 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:21:52,073 - INFO -   üìÑ Meta-Baseline: Exploring Simple Meta-Learning for Few-Shot L... - Score: 95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî∑ NODE UPDATE: researcher\n",
      "   üìö Papers: 3 found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:21:53,801 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:21:53,816 - INFO - üìù Synthesizing 4 papers with streaming...\n",
      "2025-11-16 12:22:05,979 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## R√©sum√©\n",
      "‚Ä¢ Few‚Äëshot learning studies how to train classifiers that can recognize new classes from only a handful of labeled examples ‚Äî the goal is to generalize to novel categories with minimal data (typical setups are ‚ÄúN‚Äëway K‚Äëshot‚Äù). It emphasizes task-level generalization rather than improving performance on classes seen during training [Paper 2, Paper 3].  \n",
      "‚Ä¢ Two broad families of methods are common: meta‚Äëlearning (train a learner over many small tasks to fast‚Äëadapt) and metric‚Äëlearning (learn embeddings or similarity rules to compare examples); regression‚Äëbased approaches instead predict classifiers or similarity along directional features in embedding space. These families trade off flexibility, simplicity, and assumptions about task homogeneity [Paper 1, Paper 2, Paper 3].  \n",
      "‚Ä¢ Empirical work shows simple baselines can be surprisingly strong: training on whole‚Äëclassification (standard multiclass training) or careful baseline designs can rival more complex meta‚Äëlearning schemes, suggesting the importance of evaluation protocol and strong baselines in few‚Äëshot research [Paper 1].  \n",
      "‚Ä¢ Extensions expose practical challenges: few‚Äëshot object detection adds localization and pronounced class imbalance, and diverse domains or varying numbers of labels per task require methods that handle heterogeneity without heavy task‚Äëspecific engineering. New meta‚Äëmetric and detection‚Äëfocused meta‚Äëlearning methods try to address these issues but often increase complexity or data needs [Paper 2, Paper 4].\n",
      "\n",
      "## R√©f√©rences\n",
      "[Paper 1] Meta-Baseline: Exploring Simple Meta-Learning for Few-Shot Learning - Yinbo Chen, Zhuang Liu, Huijuan Xu (2020) - http://arxiv.org/abs/2003.04390v4  \n",
      "[Paper 2] Few-shot Learning with Meta Metric Learners - Yu Cheng, Mo Yu, Xiaoxiao Guo (2019) - http://arxiv.org/abs/1901.09890v1  \n",
      "[Paper 3] Regression Networks for Meta-Learning Few-Shot Classification - Arnout Devos, Matthias Grossglauser (2019) - http://arxiv.org/abs/1905.13613v2  \n",
      "[Paper 4] Top-Related Meta-Learning Method for Few-Shot Object Detection - Qian Li, Nan Guo, Xiaochun Ye (2020) - http://arxiv.org/abs/2007.06837v6"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:22:14,141 - INFO - ‚úÖ Summary generated\n",
      "2025-11-16 12:22:15,463 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## R√©sum√©\n",
      "‚Ä¢ Few‚Äëshot learning studies how to train classifiers that can recognize new classes from only a handful of labeled examples ‚Äî the goal is to generalize to novel categories with minimal data (typical setups are ‚ÄúN‚Äëway K‚Äëshot‚Äù). It emphasizes task-level generalization rather than improving performance on classes seen during training [Paper 2, Paper 3].  \n",
      "‚Ä¢ Two broad families of methods are common: meta‚Äëlearning (train a learner over many small tasks to fast‚Äëadapt) and metric‚Äëlearning (learn embeddings or similarity rules to compare examples); regression‚Äëbased approaches instead predict classifiers or similarity along directional features in embedding space. These families trade off flexibility, simplicity, and assumptions about task homogeneity [Paper 1, Paper 2, Paper 3].  \n",
      "‚Ä¢ Empirical work shows simple baselines can be surprisingly strong: training on whole‚Äëclassification (standard multiclass training) or careful baseline designs can rival more complex meta‚Äëlearning schemes, suggesting the importance of evaluation protocol and strong baselines in few‚Äëshot research [Paper 1].  \n",
      "‚Ä¢ Extensions expose practical challenges: few‚Äëshot object detection adds localization and pronounced class imbalance, and diverse domains or varying numbers of labels per task require methods that handle heterogeneity without heavy task‚Äëspecific engineering. New meta‚Äëmetric and detection‚Äëfocused meta‚Äëlearning methods try to address these issues but often increase complexity or data needs [Paper 2, Paper 4].\n",
      "\n",
      "## R√©f√©rences\n",
      "[Paper 1] Meta-Baseline: Exploring Simple Meta-Learning for Few-Shot Learning - Yinbo Chen, Zhuang Liu, Huijuan Xu (2020) - http://arxiv.org/abs/2003.04390v4  \n",
      "[Paper 2] Few-shot Learning with Meta Metric Learners - Yu Cheng, Mo Yu, Xiaoxiao Guo (2019) - http://arxiv.org/abs/1901.09890v1  \n",
      "[Paper 3] Regression Networks for Meta-Learning Few-Shot Classification - Arnout Devos, Matthias Grossglauser (2019) - http://arxiv.org/abs/1905.13613v2  \n",
      "[Paper 4] Top-Related Meta-Learning Method for Few-Shot Object Detection - Qian Li, Nan Guo, Xiaochun Ye (2020) - http://arxiv.org/abs/2007.06837v6\n",
      "üî∑ NODE UPDATE: summarizer\n",
      "   üìù Summary generated\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Multi-mode streaming complete!\n"
     ]
    }
   ],
   "source": [
    "config_multi = {\"configurable\": {\"thread_id\": \"demo-stream-3\"}}\n",
    "\n",
    "question = \"What is few-shot learning?\"\n",
    "\n",
    "initial_state = {\n",
    "    \"query\": question,\n",
    "    \"llm_model\": LLM_MODEL,\n",
    "    \"llm_temperature\": 0,\n",
    "    \"max_papers\": 3,\n",
    "    \"max_iterations\": 2,\n",
    "}\n",
    "\n",
    "print(\"üöÄ Starting graph with multi-mode streaming...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Multiple streaming modes ‚Üí Events become tuples (mode, data)\n",
    "async for event in streaming_graph.astream(\n",
    "    initial_state,\n",
    "    config=config_multi,\n",
    "    stream_mode=[\"updates\", \"messages\", \"custom\"]  # Combine all modes\n",
    "):\n",
    "    stream_mode, data = event\n",
    "    \n",
    "    if stream_mode == \"updates\":\n",
    "        # Node-level updates\n",
    "        if isinstance(data, dict):\n",
    "            for node_name, state_update in data.items():\n",
    "                print(f\"\\nüî∑ NODE UPDATE: {node_name}\")\n",
    "                \n",
    "                if isinstance(state_update, dict):\n",
    "                    if \"refined_query\" in state_update:\n",
    "                        print(f\"   ‚ú® Refined query: {state_update['refined_query']}\")\n",
    "                    \n",
    "                    if \"papers\" in state_update:\n",
    "                        papers = state_update['papers']\n",
    "                        if isinstance(papers, list):\n",
    "                            print(f\"   üìö Papers: {len(papers)} found\")\n",
    "                    \n",
    "                    if \"summary\" in state_update and state_update[\"summary\"] != \"NEED_MORE_PAPERS\":\n",
    "                        print(f\"   üìù Summary generated\")\n",
    "    \n",
    "    elif stream_mode == \"messages\":\n",
    "        # Token-level streaming\n",
    "        message, metadata = data\n",
    "        node_name = metadata.get(\"langgraph_node\", \"\")\n",
    "        \n",
    "        # Show only summarizer tokens (comment out to see all)\n",
    "        if node_name == \"summarizer\" and hasattr(message, 'content') and message.content:\n",
    "            print(message.content, end='', flush=True)\n",
    "    \n",
    "    elif stream_mode == \"custom\":\n",
    "        # Custom tool progress\n",
    "        print(f\"üî∂ PROGRESS: {data}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Multi-mode streaming complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cedb4b",
   "metadata": {},
   "source": [
    "## Interrupts (Human-in-the-Loop)\n",
    "\n",
    "**Interrupts** pause execution for human review/approval. This enables:\n",
    "\n",
    "- ‚úÖ **Approval workflows**: Review agent decisions before proceeding\n",
    "- ‚úèÔ∏è **State editing**: Modify the plan/query before continuing  \n",
    "- ‚ùå **Cancellation**: Stop execution if the agent goes off-track\n",
    "\n",
    "**Key concepts**:\n",
    "- `interrupt_before=[\"node\"]` ‚Üí Pause **before** a node executes\n",
    "- `interrupt_after=[\"node\"]` ‚Üí Pause **after** a node completes\n",
    "- `graph.update_state()` ‚Üí Modify state at interrupt point\n",
    "- `graph.stream(None, config)` ‚Üí Resume from last checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0e7be",
   "metadata": {},
   "source": [
    "### Test 5: Basic Interruption\n",
    "\n",
    "**Pattern**: \n",
    "1. Set `interrupt_after=[\"clarifier\"]` when creating graph\n",
    "2. Run until interrupt ‚Üí receives `{'__interrupt__': ()}`\n",
    "3. Inspect state with `graph.get_state(config)`\n",
    "4. Optionally edit state with `graph.update_state()`\n",
    "5. Resume with `graph.stream(None, config)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "529f68c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:22:29,753 - INFO - Clarifying query: 'What are the key innovations in LSTM?'\n",
      "2025-11-16 12:22:29,758 - INFO - Refined query: 'LSTM gating mechanisms forget gate peephole connections'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clarifier': {'refined_query': 'LSTM gating mechanisms forget gate peephole connections', 'iteration': 0, 'messages': [HumanMessage(content='What are the key innovations in LSTM?', additional_kwargs={}, response_metadata={}, name='User'), AIMessage(content='Refined query: LSTM gating mechanisms forget gate peephole connections', additional_kwargs={}, response_metadata={}, name='Clarifier')]}}\n",
      "{'__interrupt__': ()}\n"
     ]
    }
   ],
   "source": [
    "from src.agent_graph.graph import create_graph\n",
    "\n",
    "# 1. Create graph with interrupt after clarifier node\n",
    "graph = create_graph(with_checkpointer=True, interrupt_after=[\"clarifier\"])\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"demo-interrupt-1\"}}\n",
    "\n",
    "question = \"What are the key innovations in LSTM?\"\n",
    "\n",
    "initial_state = {\n",
    "    \"query\": question,\n",
    "    \"llm_model\": LLM_MODEL,\n",
    "    \"llm_temperature\": 0,\n",
    "    \"max_papers\": 5,\n",
    "    \"max_iterations\": 2,\n",
    "}\n",
    "\n",
    "# 2. Run until first interrupt\n",
    "for event in graph.stream(initial_state, config):\n",
    "    print(event)  # You'll see {'__interrupt__': ()} when it pauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ba1b1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state values:\n",
      "{'query': 'What are the key innovations in LSTM?', 'llm_model': 'gpt-5-mini', 'llm_temperature': 0, 'max_papers': 5, 'max_iterations': 2, 'papers': [], 'messages': [HumanMessage(content='What are the key innovations in LSTM?', additional_kwargs={}, response_metadata={}, name='User'), AIMessage(content='Refined query: LSTM gating mechanisms forget gate peephole connections', additional_kwargs={}, response_metadata={}, name='Clarifier')], 'refined_query': 'LSTM gating mechanisms forget gate peephole connections', 'iteration': 0}\n",
      "\n",
      "Next node to execute:\n",
      "('researcher',)\n"
     ]
    }
   ],
   "source": [
    "# 3. Inspect state at the interrupt point\n",
    "state = graph.get_state(config)\n",
    "\n",
    "print(\"Current state values:\")\n",
    "print(state.values)  # See full current state\n",
    "\n",
    "print(\"\\nNext node to execute:\")\n",
    "print(state.next)  # Shows ('researcher',) - the next pending node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "086adfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:22:29,801 - INFO - Searching ArXiv: 'LSTM advanced architectures' (iteration 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úèÔ∏è Updated refined_query\n",
      "\n",
      "5 max_papers\n",
      "max_results tool 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:22:31,092 - INFO - Found 5 papers\n",
      "2025-11-16 12:22:31,094 - INFO - Scoring paper relevance...\n",
      "2025-11-16 12:22:31,098 - INFO -   üìÑ Vision-LSTM: xLSTM as Generic Vision Backbone... - Score: 45\n",
      "2025-11-16 12:22:31,100 - INFO -   üìÑ The application of collagen in advanced wound dressings... - Score: 1\n",
      "2025-11-16 12:22:31,102 - INFO -   üìÑ Predicting the Accuracy of Early-est Earthquake Magnitude Es... - Score: 10\n",
      "2025-11-16 12:22:33,280 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:22:33,290 - INFO -   üìÑ Advanced Drone Swarm Security by Using Blockchain Governance... - Score: 1\n",
      "2025-11-16 12:22:33,293 - INFO -   üìÑ Leveraging LSTM for Predictive Modeling of Satellite Clock B... - Score: 10\n",
      "2025-11-16 12:22:33,296 - INFO - üìù Synthesizing 5 papers...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'researcher': {'papers': [{'id': 'http://arxiv.org/abs/2406.04303v3', 'title': 'Vision-LSTM: xLSTM as Generic Vision Backbone', 'authors': ['Benedikt Alkin', 'Maximilian Beck', 'Korbinian P√∂ppel', 'Sepp Hochreiter', 'Johannes Brandstetter'], 'summary': 'Transformers are widely used as generic backbones in computer vision, despite initially introduced for natural language processing. Recently, the Long Short-Term Memory (LSTM) has been extended to a scalable and performant architecture - the xLSTM - which overcomes long-standing LSTM limitations via exponential gating and parallelizable matrix memory structure. In this report, we introduce Vision-LSTM (ViL), an adaption of the xLSTM building blocks to computer vision. ViL comprises a stack of xLSTM blocks where odd blocks process the sequence of patch tokens from top to bottom while even blocks go from bottom to top. Experiments show that ViL holds promise to be further deployed as new generic backbone for computer vision architectures.', 'url': 'http://arxiv.org/abs/2406.04303v3', 'published': '2024-06-06', 'relevance_score': 45}, {'id': 'http://arxiv.org/abs/1804.09256v2', 'title': 'The application of collagen in advanced wound dressings', 'authors': ['Giuseppe Tronci'], 'summary': 'Chronic wounds fail to proceed through an orderly and timely self healing process, resulting in cutaneous damage with full thickness in depth and leading to a major healthcare and economic burden worldwide. In the UK alone, 200,000 patients suffer from a chronic wound, whilst the global advanced wound care market is expected to reach nearly $11 million in 2022. Despite extensive research efforts so far, clinically-approved chronic wound therapies are still time-consuming, economically unaffordable and present restricted customisation. In this chapter, the role of collagen in the extracellular matrix of biological tissues and wound healing will be discussed, together with its use as building block for the manufacture of advanced wound dressings. Commercially-available collagen dressings and respective clinical performance will be presented, followed by an overview on the latest research advances in the context of multifunctional collagen systems for advanced wound care.', 'url': 'http://arxiv.org/abs/1804.09256v2', 'published': '2018-04-24', 'relevance_score': 1}, {'id': 'http://arxiv.org/abs/2104.05712v2', 'title': 'Predicting the Accuracy of Early-est Earthquake Magnitude Estimates with an LSTM Neural Network: A Preliminary Analysis', 'authors': ['Massimo Nazaria'], 'summary': 'This report presents a preliminary analysis of an LSTM neural network designed to predict the accuracy of magnitude estimates computed by Early-est during the first minutes after an earthquake occurs.', 'url': 'http://arxiv.org/abs/2104.05712v2', 'published': '2021-04-12', 'relevance_score': 10}, {'id': 'http://arxiv.org/abs/2112.15454v4', 'title': 'Advanced Drone Swarm Security by Using Blockchain Governance Game', 'authors': ['Song-Kyoo Kim'], 'summary': 'This research contributes to the security design of an advanced smart drone swarm network based on a variant of the Blockchain Governance Game (BGG), which is the theoretical game model to predict the moments of security actions before attacks, and the Strategic Alliance for Blockchain Governance Game (SABGG), which is one of the BGG variants which has been adapted to construct the best strategies to take preliminary actions based on strategic alliance for protecting smart drones in a blockchain-based swarm network. Smart drones are artificial intelligence (AI)-enabled drones which are capable of being operated autonomously without having any command center. Analytically tractable solutions from the SABGG allow us to estimate the moments of taking preliminary actions by delivering the optimal accountability of drones for preventing attacks. This advanced secured swarm network within AI-enabled drones is designed by adapting the SABGG model. This research helps users to develop a new network-architecture-level security of a smart drone swarm which is based on a decentralized network.', 'url': 'http://arxiv.org/abs/2112.15454v4', 'published': '2021-12-29', 'relevance_score': 1}, {'id': 'http://arxiv.org/abs/2411.07015v1', 'title': 'Leveraging LSTM for Predictive Modeling of Satellite Clock Bias', 'authors': ['Ahan Bhatt', 'Ishaan Mehta', 'Pravin Patidar'], 'summary': \"Satellite clock bias prediction plays a crucial role in enhancing the accuracy of satellite navigation systems. In this paper, we propose an approach utilizing Long Short-Term Memory (LSTM) networks to predict satellite clock bias. We gather data from the PRN 8 satellite of the Galileo and preprocess it to obtain a single difference sequence, crucial for normalizing the data. Normalization allows resampling of the data, ensuring that the predictions are equidistant and complete. Our methodology involves training the LSTM model on varying lengths of datasets, ranging from 7 days to 31 days. We employ a training set consisting of two days' worth of data in each case. Our LSTM model exhibits exceptional accuracy, with a Root Mean Square Error (RMSE) of 2.11 $\\\\times$ 10$^{-11}$. Notably, our approach outperforms traditional methods used for similar time-series forecasting projects, being 170 times more accurate than RNN, 2.3 $\\\\times$ 10$^7$ times more accurate than MLP, and 1.9 $\\\\times$ 10$^4$ times more accurate than ARIMA. This study holds significant potential in enhancing the accuracy and efficiency of low-power receivers used in various devices, particularly those requiring power conservation. By providing more accurate predictions of satellite clock bias, the findings of this research can be integrated into the algorithms of such devices, enabling them to function with heightened precision while conserving power. Improved accuracy in clock bias predictions ensures that low-power receivers can maintain optimal performance levels, thereby enhancing the overall reliability and effectiveness of satellite navigation systems. Consequently, this advancement holds promise for a wide range of applications, including remote areas, IoT devices, wearable technology, and other devices where power efficiency and navigation accuracy are paramount.\", 'url': 'http://arxiv.org/abs/2411.07015v1', 'published': '2024-11-11', 'relevance_score': 10}], 'iteration': 1, 'messages': [AIMessage(content='Found 5 papers on ArXiv for query: LSTM advanced architectures', additional_kwargs={}, response_metadata={}, name='Researcher')]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:22:54,172 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:22:54,195 - INFO - ‚úÖ Summary generated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'summarizer': {'summary': '## R√©sum√©\\n‚Ä¢ LSTM‚Äôs core innovation is a gated memory cell that lets networks store and selectively update information over long time spans, which mitigates vanishing gradients and enables learning long-term dependencies in sequential data [Paper 2, Paper 3].  \\n‚Ä¢ Recent architectural advances extend that idea: xLSTM introduces exponential gating and a parallelizable matrix memory structure to overcome traditional LSTM scalability and performance limits, making LSTM-style modules more competitive as large backbones (e.g., for vision) [Paper 1].  \\n‚Ä¢ In practice, LSTM variants excel at real-time sequence forecasting and noisy temporal signals, as shown by applications to early earthquake-magnitude estimation and satellite clock-bias prediction‚Äîdemonstrating robustness to short noisy windows and usefulness after domain-specific preprocessing and normalization [Paper 2, Paper 3].  \\n‚Ä¢ Deployment and performance depend heavily on implementation choices (normalization, input differencing, preprocessing, and architecture tuning) and can be further improved by domain-adapted variants or structural changes (like those in xLSTM) to increase parallelism and scalability [Paper 1, Paper 3].\\n\\n## R√©f√©rences\\n[Paper 1] Vision-LSTM: xLSTM as Generic Vision Backbone - Benedikt Alkin, Maximilian Beck, Korbinian P√∂ppel (2024-06-06) - http://arxiv.org/abs/2406.04303v3\\n\\n[Paper 2] Predicting the Accuracy of Early-est Earthquake Magnitude Estimates with an LSTM Neural Network: A Preliminary Analysis - Massimo Nazaria (2021-04-12) - http://arxiv.org/abs/2104.05712v2\\n\\n[Paper 3] Leveraging LSTM for Predictive Modeling of Satellite Clock Bias - Ahan Bhatt, Ishaan Mehta, Pravin Patidar (2024-11-11) - http://arxiv.org/abs/2411.07015v1\\n\\n[Paper 4] The application of collagen in advanced wound dressings - Giuseppe Tronci (2018-04-24) - http://arxiv.org/abs/1804.09256v2\\n\\n[Paper 5] Advanced Drone Swarm Security by Using Blockchain Governance Game - Song-Kyoo Kim (2021-12-29) - http://arxiv.org/abs/2112.15454v4', 'messages': [AIMessage(content='## R√©sum√©\\n‚Ä¢ LSTM‚Äôs core innovation is a gated memory cell that lets networks store and selectively update information over long time spans, which mitigates vanishing gradients and enables learning long-term dependencies in sequential data [Paper 2, Paper 3].  \\n‚Ä¢ Recent architectural advances extend that idea: xLSTM introduces exponential gating and a parallelizable matrix memory structure to overcome traditional LSTM scalability and performance limits, making LSTM-style modules more competitive as large backbones (e.g., for vision) [Paper 1].  \\n‚Ä¢ In practice, LSTM variants excel at real-time sequence forecasting and noisy temporal signals, as shown by applications to early earthquake-magnitude estimation and satellite clock-bias prediction‚Äîdemonstrating robustness to short noisy windows and usefulness after domain-specific preprocessing and normalization [Paper 2, Paper 3].  \\n‚Ä¢ Deployment and performance depend heavily on implementation choices (normalization, input differencing, preprocessing, and architecture tuning) and can be further improved by domain-adapted variants or structural changes (like those in xLSTM) to increase parallelism and scalability [Paper 1, Paper 3].\\n\\n## R√©f√©rences\\n[Paper 1] Vision-LSTM: xLSTM as Generic Vision Backbone - Benedikt Alkin, Maximilian Beck, Korbinian P√∂ppel (2024-06-06) - http://arxiv.org/abs/2406.04303v3\\n\\n[Paper 2] Predicting the Accuracy of Early-est Earthquake Magnitude Estimates with an LSTM Neural Network: A Preliminary Analysis - Massimo Nazaria (2021-04-12) - http://arxiv.org/abs/2104.05712v2\\n\\n[Paper 3] Leveraging LSTM for Predictive Modeling of Satellite Clock Bias - Ahan Bhatt, Ishaan Mehta, Pravin Patidar (2024-11-11) - http://arxiv.org/abs/2411.07015v1\\n\\n[Paper 4] The application of collagen in advanced wound dressings - Giuseppe Tronci (2018-04-24) - http://arxiv.org/abs/1804.09256v2\\n\\n[Paper 5] Advanced Drone Swarm Security by Using Blockchain Governance Game - Song-Kyoo Kim (2021-12-29) - http://arxiv.org/abs/2112.15454v4', additional_kwargs={}, response_metadata={}, name='Summarizer')]}}\n"
     ]
    }
   ],
   "source": [
    "# 4. Modify state before resuming\n",
    "graph.update_state(\n",
    "    config,\n",
    "    {\"refined_query\": \"LSTM advanced architectures\"},  # Edit the query\n",
    ")\n",
    "\n",
    "print(\"‚úèÔ∏è Updated refined_query\\n\")\n",
    "\n",
    "# 5. Resume execution from checkpoint\n",
    "# None = resume from last checkpoint (don't restart)\n",
    "for event in graph.stream(None, config):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7584e3a",
   "metadata": {},
   "source": [
    "### Test 6: Approval Workflow with User Input\n",
    "\n",
    "**Pattern**: Interactive human approval with three options:\n",
    "- ‚úÖ **Approve**: Continue as-is\n",
    "- ‚úèÔ∏è **Edit**: Modify the query\n",
    "- ‚ùå **Cancel**: Stop execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2b46e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:22:54,260 - INFO - Clarifying query: 'What are the key innovations in LSTM?'\n",
      "2025-11-16 12:22:54,265 - INFO - Refined query: 'LSTM gating mechanisms forget gate peephole connections'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ clarifier completed\n",
      "   Refined query: LSTM gating mechanisms forget gate peephole connections\n",
      "‚úÖ __interrupt__ completed\n",
      "\n",
      "‚è∏Ô∏è  Execution paused before researcher node\n",
      "\n",
      "üìã Proposed search query: 'LSTM gating mechanisms forget gate peephole connections'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:25:10,824 - INFO - Searching ArXiv: 'LSTM advanced' (iteration 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úèÔ∏è  Updated query to: 'LSTM advanced'\n",
      "\n",
      "‚ñ∂Ô∏è  Resuming execution...\n",
      "\n",
      "5 max_papers\n",
      "max_results tool 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:25:11,355 - INFO - Found 5 papers\n",
      "2025-11-16 12:25:11,357 - INFO - Scoring paper relevance...\n",
      "2025-11-16 12:25:11,367 - INFO -   üìÑ The application of collagen in advanced wound dressings... - Score: 1\n",
      "2025-11-16 12:25:11,369 - INFO -   üìÑ Predicting the Accuracy of Early-est Earthquake Magnitude Es... - Score: 10\n",
      "2025-11-16 12:25:11,373 - INFO -   üìÑ Vision-LSTM: xLSTM as Generic Vision Backbone... - Score: 45\n",
      "2025-11-16 12:25:11,374 - INFO -   üìÑ Leveraging LSTM for Predictive Modeling of Satellite Clock B... - Score: 10\n",
      "2025-11-16 12:25:11,376 - INFO -   üìÑ Advanced Drone Swarm Security by Using Blockchain Governance... - Score: 1\n",
      "2025-11-16 12:25:11,379 - INFO - üìù Synthesizing 5 papers...\n",
      "2025-11-16 12:25:11,382 - INFO - ‚úÖ Summary generated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ researcher completed\n",
      "‚úÖ summarizer completed\n",
      "\n",
      "üèÅ Workflow complete!\n"
     ]
    }
   ],
   "source": [
    "from src.agent_graph.graph import create_graph\n",
    "\n",
    "# Use both interrupt_before and interrupt_after for demonstration\n",
    "graph = create_graph(\n",
    "    with_checkpointer=True, \n",
    "    interrupt_before=[\"researcher\"],  # Pause BEFORE researcher runs\n",
    "    interrupt_after=[\"clarifier\"]     # Pause AFTER clarifier completes\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"demo-interrupt-2\"}}\n",
    "\n",
    "question = \"What are the key innovations in LSTM?\"\n",
    "\n",
    "initial_state = {\n",
    "    \"query\": question,\n",
    "    \"llm_model\": LLM_MODEL,\n",
    "    \"llm_temperature\": 0,\n",
    "    \"max_papers\": 5,\n",
    "    \"max_iterations\": 2,\n",
    "}\n",
    "\n",
    "# Run until interrupt\n",
    "for event in graph.stream(initial_state, config, stream_mode=\"updates\"):\n",
    "    for node_name, state_update in event.items():\n",
    "        print(f\"‚úÖ {node_name} completed\")\n",
    "        if \"refined_query\" in state_update:\n",
    "            print(f\"   Refined query: {state_update['refined_query']}\")\n",
    "\n",
    "# Execution is paused - human reviews\n",
    "print(\"\\n‚è∏Ô∏è  Execution paused before researcher node\")\n",
    "state_snapshot = graph.get_state(config)\n",
    "    \n",
    "# Get human approval/feedback\n",
    "refined_query = state_snapshot.values['refined_query']\n",
    "print(f\"\\nüìã Proposed search query: '{refined_query}'\")\n",
    "approval = input(\"Approve this query? (y/n/edit): \").strip().lower()\n",
    "\n",
    "if approval == 'n':\n",
    "    print(\"‚ùå Search cancelled\")\n",
    "elif approval == 'edit':\n",
    "    new_query = input(\"Enter new query: \").strip()\n",
    "    # Modify state before resuming\n",
    "    graph.update_state(config, {\"refined_query\": new_query})\n",
    "    print(f\"‚úèÔ∏è  Updated query to: '{new_query}'\")\n",
    "\n",
    "    # Resume execution\n",
    "    print(\"\\n‚ñ∂Ô∏è  Resuming execution...\\n\")\n",
    "    for event in graph.stream(None, config, stream_mode=\"updates\"):\n",
    "        for node_name, state_update in event.items():\n",
    "            print(f\"‚úÖ {node_name} completed\")\n",
    "else:  # 'y'\n",
    "    print(\"‚úÖ Approved - continuing...\\n\")\n",
    "    # Resume without changes\n",
    "    for event in graph.stream(None, config, stream_mode=\"updates\"):\n",
    "        for node_name, state_update in event.items():\n",
    "            print(f\"‚úÖ {node_name} completed\")\n",
    "\n",
    "print(\"\\nüèÅ Workflow complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6de9ee02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LSTM advanced'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values.get(\"refined_query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8737ce21",
   "metadata": {},
   "source": [
    "### Test 7: Interrupt Node (Built-in Approval Pattern)\n",
    "\n",
    "**Advanced pattern**: Create a dedicated **approval node** that:\n",
    "1. Uses `interrupt()` to pause execution *within* the node\n",
    "2. Returns data to the user via the interrupt value\n",
    "3. Receives user response via `Command(resume=...)`\n",
    "\n",
    "This is cleaner than `interrupt_before/after` for complex approval logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f812a756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from src.agent_graph.graph import create_graph_with_approval\n",
    "\n",
    "graph = create_graph_with_approval()\n",
    "\n",
    "# Generate graph visualization as PNG\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1874c4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:25:11,764 - INFO - Clarifying query: 'What is attention mechanism?'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting workflow with approval node...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:25:19,712 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:25:19,725 - INFO - Refined query: 'attention mechanisms neural networks survey self-attention transformer'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ clarifier completed\n",
      "‚úÖ __interrupt__ completed\n",
      "\n",
      "‚è∏Ô∏è  Approval node has paused execution\n",
      "\n",
      "The clarifier suggests this search query:\n",
      "\n",
      "   'attention mechanisms neural networks survey self-attention transformer'\n",
      "\n",
      "What would you like to do?\n",
      "  - Type 'approve' to continue\n",
      "  - Type 'edit' to modify the query\n",
      "  - Type 'cancel' to stop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:25:33,937 - INFO - Searching ArXiv: 'attention mechanism basocs' (iteration 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ñ∂Ô∏è  Resuming with your decision...\n",
      "\n",
      "‚úÖ approver completed\n",
      "5 max_papers\n",
      "max_results tool 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:25:34,327 - INFO - Found 5 papers\n",
      "2025-11-16 12:25:34,329 - INFO - Scoring paper relevance...\n",
      "2025-11-16 12:25:38,801 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:25:38,818 - INFO -   üìÑ D√©j√† vu: A Contextualized Temporal Attention Mechanism for S... - Score: 45\n",
      "2025-11-16 12:25:41,291 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:25:41,300 - INFO -   üìÑ Synthesis of Mechanism for single- and hybrid-tasks using Di... - Score: 1\n",
      "2025-11-16 12:25:43,644 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:25:43,653 - INFO -   üìÑ Synthesis of Spherical 4R Mechanism for Path Generation usin... - Score: 1\n",
      "2025-11-16 12:25:47,119 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:25:47,137 - INFO -   üìÑ Pay Attention to What You Need... - Score: 85\n",
      "2025-11-16 12:25:50,089 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:25:50,100 - INFO -   üìÑ Benign Overfitting in Token Selection of Attention Mechanism... - Score: 60\n",
      "2025-11-16 12:25:50,111 - INFO - üìù Synthesizing 5 papers...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ researcher completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:26:14,231 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:26:14,270 - INFO - ‚úÖ Summary generated\n",
      "2025-11-16 12:26:16,510 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ summarizer completed\n",
      "\n",
      "üèÅ Workflow complete!\n",
      "\n",
      "================================================================================\n",
      "üìÑ FINAL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "## R√©sum√©\n",
      "‚Ä¢ M√©canisme de base : l'attention calcule des poids (scores) qui indiquent la pertinence relative de chaque √©l√©ment d'entr√©e, puis utilise ces poids pour faire une combinaison pond√©r√©e des repr√©sentations ‚Äî cela permet au mod√®le de ¬´ se concentrer ¬ª sur les parties les plus utiles d'un contexte au moment du calcul. L'id√©e est au c≈ìur des architectures comme le Transformer et remplace/compl√®te les approches s√©quentielles classiques. [Paper 2, Paper 1]\n",
      "\n",
      "‚Ä¢ Usage dans les grands mod√®les et contexte long : dans les LLMs, l'attention permet de relier des tokens √©loign√©s, mais la gestion de contextes tr√®s longs pose des d√©fis de calcul et de qualit√© ; des travaux proposent d'adapter l'attention (s√©lection de tokens pertinents, modifications d'architecture) pour conserver l'information utile sans retrain massif. Ces approches ciblent un compromis entre pr√©cision et co√ªt pratique pour d√©ployer des mod√®les l√©gers. [Paper 1]\n",
      "\n",
      "‚Ä¢ Comportement d'apprentissage et g√©n√©ralisation : l'√©tude th√©orique de l'attention montre des ph√©nom√®nes comme un \"benign overfitting\" lors de la s√©lection de tokens ‚Äî l'attention peut apprendre √† filtrer le bruit tout en g√©n√©ralissant sous certaines conditions, mais son comportement d√©pend fortement des donn√©es et du bruit d'√©tiquetage. Comprendre ces dynamiques aide √† pr√©dire quand l'attention s√©lectionnera correctement les signaux pertinents. [Paper 2]\n",
      "\n",
      "‚Ä¢ Variantes et domaines d'application : l'attention se d√©cline (ex. attention temporelle/contextualis√©e) pour des t√¢ches s√©quentielles comme la recommandation, o√π elle int√®gre information temporelle et contexte local pour pond√©rer l'influence d'√©v√©nements pass√©s. Notez aussi que le terme \"m√©canisme\" appara√Æt dans d'autres domaines (m√©canique/optimisation) avec un sens diff√©rent ‚Äî il s'agit alors de synth√®se de m√©canismes physiques, non d'attention en apprentissage. [Paper 3, Paper 4, Paper 5]\n",
      "\n",
      "## R√©f√©rences\n",
      "[Paper 1] Pay Attention to What You Need - Yifei Gao, Shaohong Chen, Lei Wang (2023) - http://arxiv.org/abs/2307.13365v3\n",
      "\n",
      "[Paper 2] Benign Overfitting in Token Selection of Attention Mechanism - Keitaro Sakamoto, Issei Sato (2024) - http://arxiv.org/abs/2409.17625v3\n",
      "\n",
      "[Paper 3] D√©j√† vu: A Contextualized Temporal Attention Mechanism for Sequential Recommendation - Jibang Wu, Renqin Cai, Hongning Wang (2020) - http://arxiv.org/abs/2002.00741v1\n",
      "\n",
      "[Paper 4] Synthesis of Mechanism for single- and hybrid-tasks using Differential Evolution - F. Penunuri, R. Peon-Escalante, C. Villanueva (2011) - http://arxiv.org/abs/1102.2017v2\n",
      "\n",
      "[Paper 5] Synthesis of Spherical 4R Mechanism for Path Generation using Differential Evolution - F. Penunuri, R. Peon-Escalante, C. Villanueva (2011) - http://arxiv.org/abs/1112.2954v2\n",
      "\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Successfully summarized 5 papers\n"
     ]
    }
   ],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"approval-node-demo\"}}\n",
    "initial_state = {\n",
    "    \"query\": \"What is attention mechanism?\",\n",
    "    \"llm_model\": LLM_MODEL,\n",
    "    \"max_papers\": 5,\n",
    "}\n",
    "\n",
    "print(\"üöÄ Starting workflow with approval node...\\n\")\n",
    "\n",
    "# Run until the approval node interrupts\n",
    "for event in graph.stream(initial_state, config, stream_mode=\"updates\"):\n",
    "    for node_name, _ in event.items():\n",
    "        print(f\"‚úÖ {node_name} completed\")\n",
    "\n",
    "# The approval node has paused execution using interrupt()\n",
    "print(\"\\n‚è∏Ô∏è  Approval node has paused execution\")\n",
    "state = graph.get_state(config)\n",
    "\n",
    "# Extract the interrupt value (contains the message for user)\n",
    "interrupt_value = None\n",
    "for task in state.tasks:\n",
    "    if task.interrupts:\n",
    "        interrupt_value = task.interrupts[0].value\n",
    "        break\n",
    "\n",
    "if interrupt_value:\n",
    "    print(f\"\\n{interrupt_value['message']}\")\n",
    "\n",
    "# Get user decision\n",
    "user_response = input(\"\\nYour choice: \").strip().lower()\n",
    "\n",
    "# Build response based on user choice\n",
    "if user_response == \"cancel\":\n",
    "    resume_value = {\"action\": \"cancel\"}\n",
    "    print(\"\\n‚ùå Workflow cancelled by user\")\n",
    "    \n",
    "elif user_response == \"edit\":\n",
    "    new_query = input(\"Enter your improved query: \").strip()\n",
    "    resume_value = {\"action\": \"edit\", \"new_query\": new_query}\n",
    "    \n",
    "else:  # assume approve\n",
    "    resume_value = {\"action\": \"approve\"}\n",
    "\n",
    "# Resume execution by passing the response\n",
    "# Command(resume=...) sends the value back to the interrupt() call\n",
    "print(\"\\n‚ñ∂Ô∏è  Resuming with your decision...\\n\")\n",
    "\n",
    "for event in graph.stream(\n",
    "    Command(resume=resume_value),  # This \"answers\" the interrupt\n",
    "    config,\n",
    "    stream_mode=\"updates\"\n",
    "):\n",
    "    for node_name, _ in event.items():\n",
    "        print(f\"‚úÖ {node_name} completed\")\n",
    "\n",
    "print(\"\\nüèÅ Workflow complete!\")\n",
    "\n",
    "# Display final summary\n",
    "final_state = graph.get_state(config)\n",
    "\n",
    "if final_state.values.get(\"approved\", False):\n",
    "    summary = final_state.values.get(\"summary\", \"\")\n",
    "    papers = final_state.values.get(\"papers\", [])\n",
    "    \n",
    "    if summary and summary != \"NEED_MORE_PAPERS\":\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üìÑ FINAL SUMMARY\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"\\n{summary}\\n\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"\\n‚úÖ Successfully summarized {len(papers)} papers\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  Summary not generated (insufficient papers or still processing)\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Workflow was cancelled - no summary generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aa7311",
   "metadata": {},
   "source": [
    "## Time Travel (State Rewinding & Branching)\n",
    "\n",
    "**Time travel** leverages checkpoint history to:\n",
    "\n",
    "- ‚è™ **Rewind**: Go back to a previous state and modify it\n",
    "- üîÄ **Branch**: Create parallel timelines for A/B testing\n",
    "- üêõ **Debug**: Replay from any point in execution history\n",
    "\n",
    "**Key concepts**:\n",
    "- `graph.get_state_history(config)` ‚Üí Access all checkpoints for a thread\n",
    "- `graph.update_state(..., as_node=\"node_name\")` ‚Üí Rewind to after that node ran\n",
    "- Different `thread_id` ‚Üí Independent execution branches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c21cd5",
   "metadata": {},
   "source": [
    "### Test 8: Rewind and Fix\n",
    "\n",
    "**Scenario**: Agent runs with ambiguous query, produces poor results. We rewind to the clarifier step and fix the query.\n",
    "\n",
    "**Pattern**:\n",
    "1. Run workflow to completion\n",
    "2. Browse checkpoint history\n",
    "3. Find the node to rewind to\n",
    "4. Use `update_state(..., as_node=\"clarifier\")` to rewind\n",
    "5. Re-run from that point forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "294fcaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:26:16,639 - INFO - Clarifying query: 'What are transformers?'\n",
      "2025-11-16 12:26:16,643 - INFO - Refined query: 'Transformer neural network architecture attention mechanism Vaswani'\n",
      "2025-11-16 12:26:16,644 - INFO - Searching ArXiv: 'Transformer neural network architecture attention mechanism Vaswani' (iteration 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running workflow with ambiguous query...\n",
      "\n",
      "‚úÖ clarifier completed\n",
      "   Query: Transformer neural network architecture attention mechanism Vaswani\n",
      "5 max_papers\n",
      "max_results tool 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:26:16,726 - INFO - Found 5 papers\n",
      "2025-11-16 12:26:16,727 - INFO - Scoring paper relevance...\n",
      "2025-11-16 12:26:16,731 - INFO -   üìÑ Music Transformer... - Score: 45\n",
      "2025-11-16 12:26:16,736 - INFO -   üìÑ A Tutorial about Random Neural Networks in Supervised Learni... - Score: 3\n",
      "2025-11-16 12:26:16,739 - INFO -   üìÑ Architectural Implications of Graph Neural Networks... - Score: 5\n",
      "2025-11-16 12:26:16,741 - INFO -   üìÑ Partial Connection Based on Channel Attention for Differenti... - Score: 5\n",
      "2025-11-16 12:26:16,743 - INFO -   üìÑ Trading with the Momentum Transformer: An Intelligent and In... - Score: 30\n",
      "2025-11-16 12:26:16,744 - INFO - üìù Synthesizing 5 papers...\n",
      "2025-11-16 12:26:16,748 - INFO - ‚úÖ Summary generated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ researcher completed\n",
      "‚úÖ summarizer completed\n",
      "\n",
      "üìÑ FINAL SUMMARY\n",
      "## R√©sum√©\n",
      "‚Ä¢ Transformers are neural sequence models that replace recurrence with self-attention, giving each position direct, learned connections to all others; this enables modeling long-range dependencies and efficient parallel training [Paper 1, Paper 2].  \n",
      "‚Ä¢ They are widely adaptable: variants like the Music Transformer use attention to capture musical repetition and structure over long timescales, while the Momentum Transformer applies attention to financial time series for interpretable mo...\n"
     ]
    }
   ],
   "source": [
    "from src.agent_graph.graph import create_graph\n",
    "\n",
    "graph = create_graph(with_checkpointer=True)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"time-travel-demo\"}}\n",
    "initial_state = {\n",
    "    \"query\": \"What are transformers?\",  # Ambiguous! Could mean neural nets or electrical\n",
    "    \"llm_model\": LLM_MODEL,\n",
    "    \"max_papers\": 5,\n",
    "}\n",
    "\n",
    "print(\"üöÄ Running workflow with ambiguous query...\\n\")\n",
    "\n",
    "# Run to completion\n",
    "for event in graph.stream(initial_state, config, stream_mode=\"updates\"):\n",
    "    for node_name, state_update in event.items():\n",
    "        print(f\"‚úÖ {node_name} completed\")\n",
    "        if \"refined_query\" in state_update:\n",
    "            print(f\"   Query: {state_update['refined_query']}\")\n",
    "\n",
    "# Check the final summary\n",
    "final_state = graph.get_state(config)\n",
    "summary = final_state.values.get('summary', '')\n",
    "\n",
    "print(\"\\nüìÑ FINAL SUMMARY\")\n",
    "print(summary[:500] + \"...\" if len(summary) > 500 else summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ed63e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìú Checkpoint History:\n",
      "\n",
      "üìç After CLARIFIER:\n",
      "   Query: Transformer neural network architecture attention mechanism ...\n",
      "   Checkpoint ID: 1f0c2df1-1052-6940-8...\n",
      "\n",
      "üìç After RESEARCHER:\n",
      "   Papers found: 5\n",
      "   Checkpoint ID: 1f0c2df1-1052-6940-8...\n",
      "\n",
      "üìç After SUMMARIZER:\n",
      "   Summary length: 1908 chars\n",
      "   Checkpoint ID: 1f0c2df1-1052-6940-8...\n",
      "\n",
      "‚è™ Rewinding to clarifier to fix ambiguous query...\n",
      "\n",
      "‚úèÔ∏è  Updated query to be more specific: 'transformer electrical power systems'\n"
     ]
    }
   ],
   "source": [
    "# Browse checkpoint history\n",
    "history = list(graph.get_state_history(config))\n",
    "\n",
    "print(\"üìú Checkpoint History:\\n\")\n",
    "\n",
    "# Find key checkpoints (after each node)\n",
    "clarifier_checkpoint = None\n",
    "researcher_checkpoint = None\n",
    "summarizer_checkpoint = None\n",
    "\n",
    "for checkpoint in history:\n",
    "    # Check which node produced this checkpoint\n",
    "    if \"refined_query\" in checkpoint.values and not clarifier_checkpoint:\n",
    "        clarifier_checkpoint = checkpoint\n",
    "        print(f\"üìç After CLARIFIER:\")\n",
    "        print(f\"   Query: {checkpoint.values['refined_query'][:60]}...\")\n",
    "        print(f\"   Checkpoint ID: {checkpoint.config['configurable']['checkpoint_id'][:20]}...\\n\")\n",
    "    \n",
    "    if \"papers\" in checkpoint.values and checkpoint.values.get(\"papers\") and not researcher_checkpoint:\n",
    "        researcher_checkpoint = checkpoint\n",
    "        print(f\"üìç After RESEARCHER:\")\n",
    "        print(f\"   Papers found: {len(checkpoint.values['papers'])}\")\n",
    "        print(f\"   Checkpoint ID: {checkpoint.config['configurable']['checkpoint_id'][:20]}...\\n\")\n",
    "    \n",
    "    if \"summary\" in checkpoint.values and checkpoint.values.get(\"summary\") != \"NEED_MORE_PAPERS\" and not summarizer_checkpoint:\n",
    "        summarizer_checkpoint = checkpoint\n",
    "        print(f\"üìç After SUMMARIZER:\")\n",
    "        print(f\"   Summary length: {len(checkpoint.values['summary'])} chars\")\n",
    "        print(f\"   Checkpoint ID: {checkpoint.config['configurable']['checkpoint_id'][:20]}...\\n\")\n",
    "\n",
    "# Rewind to clarifier node and fix the query\n",
    "print(\"‚è™ Rewinding to clarifier to fix ambiguous query...\\n\")\n",
    "\n",
    "# as_node=\"clarifier\" ‚Üí Rewind to right after clarifier ran\n",
    "# Clear downstream state to force re-execution\n",
    "graph.update_state(\n",
    "    config,\n",
    "    {\n",
    "        \"refined_query\": \"transformer electrical power systems\",\n",
    "        \"papers\": [],      # Clear papers so researcher re-runs\n",
    "        \"summary\": \"\",     # Clear summary so summarizer re-runs\n",
    "        \"iteration\": 0\n",
    "    },\n",
    "    as_node=\"clarifier\"  # Act as if clarifier just produced this state\n",
    ")\n",
    "\n",
    "print(\"‚úèÔ∏è  Updated query to be more specific: 'transformer electrical power systems'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e75d1b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current refined_query: transformer electrical power systems\n",
      "Papers in state: 0\n",
      "Next node to run: ('researcher',)\n"
     ]
    }
   ],
   "source": [
    "# Verify the rewind worked\n",
    "current_state = graph.get_state(config)\n",
    "\n",
    "print(\"Current refined_query:\", current_state.values.get(\"refined_query\"))\n",
    "print(\"Papers in state:\", len(current_state.values.get(\"papers\", [])))\n",
    "print(\"Next node to run:\", current_state.next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdef9ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Remove this cell if not needed for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be8f9778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:26:16,841 - INFO - Searching ArXiv: 'transformer electrical power systems' (iteration 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ñ∂Ô∏è  Re-running from researcher node with corrected query...\n",
      "\n",
      "5 max_papers\n",
      "max_results tool 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:26:17,481 - INFO - Found 5 papers\n",
      "2025-11-16 12:26:17,482 - INFO - Scoring paper relevance...\n",
      "2025-11-16 12:26:21,425 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:26:21,438 - INFO -   üìÑ Parameterized Linear Power Flow for High Fidelity Voltage So... - Score: 3\n",
      "2025-11-16 12:26:24,363 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:26:24,389 - INFO -   üìÑ A Strategy for Power System Stability Improvement via Contro... - Score: 1\n",
      "2025-11-16 12:26:27,057 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:26:27,068 - INFO -   üìÑ PINNSim: A Simulator for Power System Dynamics based on Phys... - Score: 2\n",
      "2025-11-16 12:26:31,059 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:26:31,067 - INFO -   üìÑ Electric Vehicle Attack Impact on Power Grid Operation... - Score: 5\n",
      "2025-11-16 12:26:34,164 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:26:34,172 - INFO -   üìÑ Dynamic State Estimation for Integrated Natural Gas and Elec... - Score: 10\n",
      "2025-11-16 12:26:35,630 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:26:35,638 - INFO - üìù Synthesizing 5 papers...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ researcher (re-executed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:27:02,900 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-16 12:27:02,936 - INFO - ‚úÖ Summary generated\n",
      "2025-11-16 12:27:05,138 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ summarizer (re-executed)\n",
      "\n",
      "üìÑ NEW SUMMARY (after time travel)\n",
      "## R√©sum√©\n",
      "‚Ä¢ The set of provided papers do not define or study ‚Äútransformers‚Äù (neither the electromagnetic device for voltage conversion nor the machine‚Äëlearning Transformer model). Instead, they address power‚Äësystem modeling, dynamics, gas‚Äìelectric coupling, electric‚Äëvehicle impacts, and simulation methods, so they cannot directly answer ‚ÄúWhat are transformers?‚Äù if you meant that term; ask and I will summarize transformers specifically [Paper 1, Paper 2, Paper 3, Paper 4, Paper 5].  \n",
      "‚Ä¢ Integrate...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n‚ñ∂Ô∏è  Re-running from researcher node with corrected query...\\n\")\n",
    "\n",
    "# Resume from checkpoint - graph will execute researcher ‚Üí summarizer\n",
    "for event in graph.stream(None, config, stream_mode=\"updates\"):\n",
    "    for node_name, state_update in event.items():\n",
    "        print(f\"‚úÖ {node_name} (re-executed)\")\n",
    "\n",
    "# Check the new result\n",
    "new_final_state = graph.get_state(config)\n",
    "new_summary = new_final_state.values['summary']\n",
    "\n",
    "print(\"\\nüìÑ NEW SUMMARY (after time travel)\")\n",
    "print(new_summary[:500] + \"...\" if len(new_summary) > 500 else new_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae184154",
   "metadata": {},
   "source": [
    "### Test 9: Parallel Branches (A/B Testing)\n",
    "\n",
    "**Scenario**: Run the same workflow with different parameters by branching from a checkpoint.\n",
    "\n",
    "**Use case**: \n",
    "- Compare results with different `max_papers` settings\n",
    "- Test different prompting strategies\n",
    "- A/B test workflow variations\n",
    "\n",
    "**Key insight**: Both branches reuse the expensive clarifier step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f5d89f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:27:05,475 - INFO - Clarifying query: 'What are transformers?'\n",
      "2025-11-16 12:27:05,479 - INFO - Refined query: 'Transformer neural network architecture attention mechanism Vaswani'\n",
      "2025-11-16 12:27:05,480 - INFO - Searching ArXiv: 'Transformer neural network architecture attention mechanism Vaswani' (iteration 0)\n",
      "2025-11-16 12:27:05,481 - INFO - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=Transformer+neural+network+architecture+attention+mechanism+Vaswani&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=5\n",
      "2025-11-16 12:27:05,641 - INFO - Got first page: 5 of 736477 total results\n",
      "2025-11-16 12:27:05,644 - INFO - Found 5 papers\n",
      "2025-11-16 12:27:05,644 - INFO - Scoring paper relevance...\n",
      "2025-11-16 12:27:05,647 - INFO -   üìÑ Music Transformer... - Score: 45\n",
      "2025-11-16 12:27:05,649 - INFO -   üìÑ A Tutorial about Random Neural Networks in Supervised Learni... - Score: 3\n",
      "2025-11-16 12:27:05,651 - INFO -   üìÑ Architectural Implications of Graph Neural Networks... - Score: 5\n",
      "2025-11-16 12:27:05,652 - INFO -   üìÑ Partial Connection Based on Channel Attention for Differenti... - Score: 5\n",
      "2025-11-16 12:27:05,654 - INFO -   üìÑ Trading with the Momentum Transformer: An Intelligent and In... - Score: 30\n",
      "2025-11-16 12:27:05,656 - INFO - üìù Synthesizing 5 papers...\n",
      "2025-11-16 12:27:05,658 - INFO - ‚úÖ Summary generated\n",
      "2025-11-16 12:27:05,665 - INFO - Searching ArXiv: 'Transformer neural network architecture attention mechanism Vaswani' (iteration 0)\n",
      "2025-11-16 12:27:05,666 - INFO - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=Transformer+neural+network+architecture+attention+mechanism+Vaswani&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=5\n",
      "2025-11-16 12:27:05,757 - INFO - Got first page: 5 of 736477 total results\n",
      "2025-11-16 12:27:05,760 - INFO - Found 5 papers\n",
      "2025-11-16 12:27:05,760 - INFO - Scoring paper relevance...\n",
      "2025-11-16 12:27:05,764 - INFO -   üìÑ Music Transformer... - Score: 45\n",
      "2025-11-16 12:27:05,768 - INFO -   üìÑ A Tutorial about Random Neural Networks in Supervised Learni... - Score: 3\n",
      "2025-11-16 12:27:05,774 - INFO -   üìÑ Architectural Implications of Graph Neural Networks... - Score: 5\n",
      "2025-11-16 12:27:05,782 - INFO -   üìÑ Partial Connection Based on Channel Attention for Differenti... - Score: 5\n",
      "2025-11-16 12:27:05,808 - INFO -   üìÑ Trading with the Momentum Transformer: An Intelligent and In... - Score: 30\n",
      "2025-11-16 12:27:05,817 - INFO - üìù Synthesizing 5 papers...\n",
      "2025-11-16 12:27:05,828 - INFO - ‚úÖ Summary generated\n",
      "2025-11-16 12:27:05,842 - INFO - Searching ArXiv: 'Transformer neural network architecture attention mechanism Vaswani' (iteration 0)\n",
      "2025-11-16 12:27:05,844 - INFO - Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=Transformer+neural+network+architecture+attention+mechanism+Vaswani&id_list=&sortBy=relevance&sortOrder=descending&start=0&max_results=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Base run complete. Clarifier produced: 'Transformer neural network architecture attention mechanism Vaswani'\n",
      "\n",
      "Now creating parallel branches to test different max_papers values...\n",
      "\n",
      "Running Branch A (5 papers)...\n",
      "Running Branch B (10 papers)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 12:27:06,001 - INFO - Got first page: 10 of 736477 total results\n",
      "2025-11-16 12:27:06,004 - INFO - Found 10 papers\n",
      "2025-11-16 12:27:06,006 - INFO - Scoring paper relevance...\n",
      "2025-11-16 12:27:06,009 - INFO -   üìÑ Music Transformer... - Score: 45\n",
      "2025-11-16 12:27:06,012 - INFO -   üìÑ A Tutorial about Random Neural Networks in Supervised Learni... - Score: 3\n",
      "2025-11-16 12:27:06,014 - INFO -   üìÑ Architectural Implications of Graph Neural Networks... - Score: 5\n",
      "2025-11-16 12:27:06,018 - INFO -   üìÑ Partial Connection Based on Channel Attention for Differenti... - Score: 5\n",
      "2025-11-16 12:27:06,021 - INFO -   üìÑ Trading with the Momentum Transformer: An Intelligent and In... - Score: 30\n",
      "2025-11-16 12:27:06,024 - INFO -   üìÑ Hierarchical Attentional Hybrid Neural Networks for Document... - Score: 20\n",
      "2025-11-16 12:27:06,027 - INFO -   üìÑ Predicting concentration levels of air pollutants by transfe... - Score: 1\n",
      "2025-11-16 12:27:06,031 - INFO -   üìÑ Neural Architecture Transfer... - Score: 8\n",
      "2025-11-16 12:27:06,033 - INFO -   üìÑ Learning Neural Network Architectures using Backpropagation... - Score: 10\n",
      "2025-11-16 12:27:06,036 - INFO -   üìÑ Transformer-based Personalized Attention Mechanism for Medic... - Score: 30\n",
      "2025-11-16 12:27:06,039 - INFO - üìù Synthesizing 10 papers...\n",
      "2025-11-16 12:27:06,042 - INFO - ‚úÖ Summary generated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Comparison:\n",
      "  Branch A (5 papers):  5 papers, 1908 char summary\n",
      "  Branch B (10 papers): 10 papers, 3172 char summary\n",
      "\n",
      "Both branches reused the same clarifier result, saving 1 LLM call!\n"
     ]
    }
   ],
   "source": [
    "from src.agent_graph.graph import create_graph\n",
    "\n",
    "graph = create_graph(with_checkpointer=True)\n",
    "\n",
    "initial_state = {\n",
    "    \"query\": \"What are transformers?\",\n",
    "    \"llm_model\": LLM_MODEL,\n",
    "    \"max_papers\": 5,\n",
    "}\n",
    "\n",
    "# Run base workflow once\n",
    "base_config = {\"configurable\": {\"thread_id\": \"ab-test-base\"}}\n",
    "for event in graph.stream(initial_state, base_config):\n",
    "    pass\n",
    "\n",
    "# Find the clarifier checkpoint (the expensive LLM call we want to reuse)\n",
    "history = list(graph.get_state_history(base_config))\n",
    "clarifier_checkpoint = None\n",
    "for checkpoint in reversed(history):  # Start from oldest\n",
    "    if \"refined_query\" in checkpoint.values and checkpoint.values.get(\"refined_query\"):\n",
    "        clarifier_checkpoint = checkpoint\n",
    "        break\n",
    "\n",
    "print(f\"‚úÖ Base run complete. Clarifier produced: '{clarifier_checkpoint.values['refined_query']}'\")\n",
    "print(f\"\\nNow creating parallel branches to test different max_papers values...\\n\")\n",
    "\n",
    "# Branch A: Test with 5 papers\n",
    "branch_a_config = {\"configurable\": {\"thread_id\": \"branch-5-papers\"}}\n",
    "graph.update_state(\n",
    "    branch_a_config,\n",
    "    {\n",
    "        **clarifier_checkpoint.values,  # Copy the refined query\n",
    "        \"max_papers\": 5,                # Set branch-specific parameter\n",
    "        \"papers\": [],                   # Clear downstream state\n",
    "        \"summary\": \"\"\n",
    "    },\n",
    "    as_node=\"clarifier\"  # Start from after clarifier\n",
    ")\n",
    "\n",
    "# Branch B: Test with 10 papers\n",
    "branch_b_config = {\"configurable\": {\"thread_id\": \"branch-10-papers\"}}\n",
    "graph.update_state(\n",
    "    branch_b_config,\n",
    "    {\n",
    "        **clarifier_checkpoint.values,\n",
    "        \"max_papers\": 10,  # Different parameter\n",
    "        \"papers\": [],\n",
    "        \"summary\": \"\"\n",
    "    },\n",
    "    as_node=\"clarifier\"\n",
    ")\n",
    "\n",
    "# Run both branches (they share the clarifier's work!)\n",
    "print(\"Running Branch A (5 papers)...\")\n",
    "for event in graph.stream(None, branch_a_config):\n",
    "    pass\n",
    "\n",
    "print(\"Running Branch B (10 papers)...\")\n",
    "for event in graph.stream(None, branch_b_config):\n",
    "    pass\n",
    "\n",
    "# Compare results\n",
    "result_a = graph.get_state(branch_a_config).values\n",
    "result_b = graph.get_state(branch_b_config).values\n",
    "\n",
    "print(f\"\\nüìä Comparison:\")\n",
    "print(f\"  Branch A (5 papers):  {len(result_a['papers'])} papers, {len(result_a['summary'])} char summary\")\n",
    "print(f\"  Branch B (10 papers): {len(result_b['papers'])} papers, {len(result_b['summary'])} char summary\")\n",
    "print(f\"\\nBoth branches reused the same clarifier result, saving 1 LLM call!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scientific-graph-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
